{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI \n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response_to_check_logprob = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': 'You are a helpful assistant that can classify a given question into one of the following categories: \"Math\", \"Science\", \"History\". Provide only the category name as your final answer and a brief explanation of why you chose that category. (single line explanation)'},\n",
    "        {'role': 'user', 'content': f'Please classify the following question: {input} Your response **must be** one of the categories mentioned above.'}\n",
    "    ],\n",
    "    logprobs=True,\n",
    "    top_logprobs=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AJ2p4RBd8EGPeFlPPPu74nsIuq63k', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-2.1731672, top_logprobs=[TopLogprob(token='Science', bytes=[83, 99, 105, 101, 110, 99, 101], logprob=-0.67316717), TopLogprob(token='Math', bytes=[77, 97, 116, 104], logprob=-1.1731672), TopLogprob(token='The', bytes=[84, 104, 101], logprob=-2.1731672), TopLogprob(token='This', bytes=[84, 104, 105, 115], logprob=-3.6731672), TopLogprob(token='None', bytes=[78, 111, 110, 101], logprob=-3.9231672), TopLogprob(token='It', bytes=[73, 116], logprob=-5.173167), TopLogprob(token='I', bytes=[73], logprob=-5.673167), TopLogprob(token=\"I'm\", bytes=[73, 39, 109], logprob=-5.923167)]), ChatCompletionTokenLogprob(token=' input', bytes=[32, 105, 110, 112, 117, 116], logprob=-1.0813488, top_logprobs=[TopLogprob(token=' input', bytes=[32, 105, 110, 112, 117, 116], logprob=-1.0813488), TopLogprob(token=' given', bytes=[32, 103, 105, 118, 101, 110], logprob=-1.7063488), TopLogprob(token=' question', bytes=[32, 113, 117, 101, 115, 116, 105, 111, 110], logprob=-1.7063488), TopLogprob(token=' provided', bytes=[32, 112, 114, 111, 118, 105, 100, 101, 100], logprob=-1.9563488), TopLogprob(token=' text', bytes=[32, 116, 101, 120, 116], logprob=-2.456349), TopLogprob(token=' prompt', bytes=[32, 112, 114, 111, 109, 112, 116], logprob=-3.456349), TopLogprob(token=' content', bytes=[32, 99, 111, 110, 116, 101, 110, 116], logprob=-3.706349), TopLogprob(token=' statement', bytes=[32, 115, 116, 97, 116, 101, 109, 101, 110, 116], logprob=-5.331349)]), ChatCompletionTokenLogprob(token=' does', bytes=[32, 100, 111, 101, 115], logprob=-1.8378587, top_logprobs=[TopLogprob(token=' provided', bytes=[32, 112, 114, 111, 118, 105, 100, 101, 100], logprob=-0.5878586), TopLogprob(token=' does', bytes=[32, 100, 111, 101, 115], logprob=-1.8378587), TopLogprob(token=' appears', bytes=[32, 97, 112, 112, 101, 97, 114, 115], logprob=-2.0878587), TopLogprob(token=' seems', bytes=[32, 115, 101, 101, 109, 115], logprob=-3.0878587), TopLogprob(token=' is', bytes=[32, 105, 115], logprob=-3.3378587), TopLogprob(token=' given', bytes=[32, 103, 105, 118, 101, 110], logprob=-3.3378587), TopLogprob(token=\" doesn't\", bytes=[32, 100, 111, 101, 115, 110, 39, 116], logprob=-3.9628587), TopLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-4.4628587)]), ChatCompletionTokenLogprob(token=' not', bytes=[32, 110, 111, 116], logprob=-2.220075e-06, top_logprobs=[TopLogprob(token=' not', bytes=[32, 110, 111, 116], logprob=-2.220075e-06), TopLogprob(token=' appear', bytes=[32, 97, 112, 112, 101, 97, 114], logprob=-13.875002), TopLogprob(token=' seem', bytes=[32, 115, 101, 101, 109], logprob=-15.000002), TopLogprob(token=' **', bytes=[32, 42, 42], logprob=-15.250002), TopLogprob(token='not', bytes=[110, 111, 116], logprob=-15.875002), TopLogprob(token=\"'t\", bytes=[39, 116], logprob=-16.375002), TopLogprob(token=' no', bytes=[32, 110, 111], logprob=-16.875002), TopLogprob(token=\"n't\", bytes=[110, 39, 116], logprob=-17.000002)]), ChatCompletionTokenLogprob(token=' appear', bytes=[32, 97, 112, 112, 101, 97, 114], logprob=-0.8023535, top_logprobs=[TopLogprob(token=' appear', bytes=[32, 97, 112, 112, 101, 97, 114], logprob=-0.8023535), TopLogprob(token=' contain', bytes=[32, 99, 111, 110, 116, 97, 105, 110], logprob=-1.6773535), TopLogprob(token=' seem', bytes=[32, 115, 101, 101, 109], logprob=-2.1773534), TopLogprob(token=' resemble', bytes=[32, 114, 101, 115, 101, 109, 98, 108, 101], logprob=-2.4273534), TopLogprob(token=' represent', bytes=[32, 114, 101, 112, 114, 101, 115, 101, 110, 116], logprob=-2.9273534), TopLogprob(token=' form', bytes=[32, 102, 111, 114, 109], logprob=-3.5523534), TopLogprob(token=' provide', bytes=[32, 112, 114, 111, 118, 105, 100, 101], logprob=-3.6773534), TopLogprob(token=' present', bytes=[32, 112, 114, 101, 115, 101, 110, 116], logprob=-4.4273534)]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.005310012, top_logprobs=[TopLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.005310012), TopLogprob(token=' as', bytes=[32, 97, 115], logprob=-5.25531), TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-10.75531), TopLogprob(token=' like', bytes=[32, 108, 105, 107, 101], logprob=-11.13031), TopLogprob(token=' related', bytes=[32, 114, 101, 108, 97, 116, 101, 100], logprob=-11.88031), TopLogprob(token=' directly', bytes=[32, 100, 105, 114, 101, 99, 116, 108, 121], logprob=-11.88031), TopLogprob(token=' relevant', bytes=[32, 114, 101, 108, 101, 118, 97, 110, 116], logprob=-12.13031), TopLogprob(token=' formatted', bytes=[32, 102, 111, 114, 109, 97, 116, 116, 101, 100], logprob=-12.25531)]), ChatCompletionTokenLogprob(token=' be', bytes=[32, 98, 101], logprob=-0.018437408, top_logprobs=[TopLogprob(token=' be', bytes=[32, 98, 101], logprob=-0.018437408), TopLogprob(token=' contain', bytes=[32, 99, 111, 110, 116, 97, 105, 110], logprob=-4.2684374), TopLogprob(token=' represent', bytes=[32, 114, 101, 112, 114, 101, 115, 101, 110, 116], logprob=-6.6434374), TopLogprob(token=' form', bytes=[32, 102, 111, 114, 109], logprob=-6.8934374), TopLogprob(token=' resemble', bytes=[32, 114, 101, 115, 101, 109, 98, 108, 101], logprob=-8.143437), TopLogprob(token=' correspond', bytes=[32, 99, 111, 114, 114, 101, 115, 112, 111, 110, 100], logprob=-8.268437), TopLogprob(token=' include', bytes=[32, 105, 110, 99, 108, 117, 100, 101], logprob=-8.393437), TopLogprob(token=' present', bytes=[32, 112, 114, 101, 115, 101, 110, 116], logprob=-8.768437)]), ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.01343597, top_logprobs=[TopLogprob(token=' a', bytes=[32, 97], logprob=-0.01343597), TopLogprob(token=' an', bytes=[32, 97, 110], logprob=-4.638436), TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-5.888436), TopLogprob(token=' formatted', bytes=[32, 102, 111, 114, 109, 97, 116, 116, 101, 100], logprob=-8.263436), TopLogprob(token=' formulated', bytes=[32, 102, 111, 114, 109, 117, 108, 97, 116, 101, 100], logprob=-9.013436), TopLogprob(token=' related', bytes=[32, 114, 101, 108, 97, 116, 101, 100], logprob=-9.513436), TopLogprob(token=' phr', bytes=[32, 112, 104, 114], logprob=-9.763436), TopLogprob(token=' structured', bytes=[32, 115, 116, 114, 117, 99, 116, 117, 114, 101, 100], logprob=-9.888436)]), ChatCompletionTokenLogprob(token=' valid', bytes=[32, 118, 97, 108, 105, 100], logprob=-1.1622796, top_logprobs=[TopLogprob(token=' valid', bytes=[32, 118, 97, 108, 105, 100], logprob=-1.1622796), TopLogprob(token=' question', bytes=[32, 113, 117, 101, 115, 116, 105, 111, 110], logprob=-1.1622796), TopLogprob(token=' clear', bytes=[32, 99, 108, 101, 97, 114], logprob=-2.4122796), TopLogprob(token=' coherent', bytes=[32, 99, 111, 104, 101, 114, 101, 110, 116], logprob=-2.5372796), TopLogprob(token=' typical', bytes=[32, 116, 121, 112, 105, 99, 97, 108], logprob=-2.6622796), TopLogprob(token=' recognizable', bytes=[32, 114, 101, 99, 111, 103, 110, 105, 122, 97, 98, 108, 101], logprob=-3.6622796), TopLogprob(token=' standard', bytes=[32, 115, 116, 97, 110, 100, 97, 114, 100], logprob=-4.0372796), TopLogprob(token=' proper', bytes=[32, 112, 114, 111, 112, 101, 114], logprob=-4.4122796)]), ChatCompletionTokenLogprob(token=' question', bytes=[32, 113, 117, 101, 115, 116, 105, 111, 110], logprob=-0.0461531, top_logprobs=[TopLogprob(token=' question', bytes=[32, 113, 117, 101, 115, 116, 105, 111, 110], logprob=-0.0461531), TopLogprob(token=' or', bytes=[32, 111, 114], logprob=-3.421153), TopLogprob(token=',', bytes=[44], logprob=-5.046153), TopLogprob(token=' natural', bytes=[32, 110, 97, 116, 117, 114, 97, 108], logprob=-6.171153), TopLogprob(token=' human', bytes=[32, 104, 117, 109, 97, 110], logprob=-6.421153), TopLogprob(token='ly', bytes=[108, 121], logprob=-8.296153), TopLogprob(token=' user', bytes=[32, 117, 115, 101, 114], logprob=-8.796153), TopLogprob(token=' class', bytes=[32, 99, 108, 97, 115, 115], logprob=-8.921153)]), ChatCompletionTokenLogprob(token=' related', bytes=[32, 114, 101, 108, 97, 116, 101, 100], logprob=-1.3656905, top_logprobs=[TopLogprob(token=' related', bytes=[32, 114, 101, 108, 97, 116, 101, 100], logprob=-1.3656905), TopLogprob(token=',', bytes=[44], logprob=-1.8656905), TopLogprob(token=' that', bytes=[32, 116, 104, 97, 116], logprob=-1.8656905), TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-2.6156905), TopLogprob(token=' but', bytes=[32, 98, 117, 116], logprob=-2.6156905), TopLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-3.1156905), TopLogprob(token=' from', bytes=[32, 102, 114, 111, 109], logprob=-3.1156905), TopLogprob(token='.', bytes=[46], logprob=-3.2406905)]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.0007904516, top_logprobs=[TopLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.0007904516), TopLogprob(token=' directly', bytes=[32, 100, 105, 114, 101, 99, 116, 108, 121], logprob=-7.3757906), TopLogprob(token=' specifically', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 99, 97, 108, 108, 121], logprob=-9.125791), TopLogprob(token=' explicitly', bytes=[32, 101, 120, 112, 108, 105, 99, 105, 116, 108, 121], logprob=-10.250791), TopLogprob(token=' clearly', bytes=[32, 99, 108, 101, 97, 114, 108, 121], logprob=-11.625791), TopLogprob(token=' strictly', bytes=[32, 115, 116, 114, 105, 99, 116, 108, 121], logprob=-12.750791), TopLogprob(token=' any', bytes=[32, 97, 110, 121], logprob=-13.750791), TopLogprob(token=' content', bytes=[32, 99, 111, 110, 116, 101, 110, 116], logprob=-14.125791)]), ChatCompletionTokenLogprob(token=' any', bytes=[32, 97, 110, 121], logprob=-0.7639222, top_logprobs=[TopLogprob(token=' any', bytes=[32, 97, 110, 121], logprob=-0.7639222), TopLogprob(token=' \"', bytes=[32, 34], logprob=-1.3889222), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-1.8889222), TopLogprob(token=' Math', bytes=[32, 77, 97, 116, 104], logprob=-2.2639222), TopLogprob(token=' a', bytes=[32, 97], logprob=-4.013922), TopLogprob(token=' one', bytes=[32, 111, 110, 101], logprob=-4.888922), TopLogprob(token=' specific', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 99], logprob=-6.763922), TopLogprob(token=' math', bytes=[32, 109, 97, 116, 104], logprob=-6.763922)]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.271632, top_logprobs=[TopLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.271632), TopLogprob(token=' category', bytes=[32, 99, 97, 116, 101, 103, 111, 114, 121], logprob=-2.021632), TopLogprob(token=' specific', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 99], logprob=-2.521632), TopLogprob(token=' subject', bytes=[32, 115, 117, 98, 106, 101, 99, 116], logprob=-5.521632), TopLogprob(token=' known', bytes=[32, 107, 110, 111, 119, 110], logprob=-5.521632), TopLogprob(token=' specified', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 101, 100], logprob=-6.021632), TopLogprob(token=' academic', bytes=[32, 97, 99, 97, 100, 101, 109, 105, 99], logprob=-6.396632), TopLogprob(token=' particular', bytes=[32, 112, 97, 114, 116, 105, 99, 117, 108, 97, 114], logprob=-6.646632)]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.0011067559, top_logprobs=[TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.0011067559), TopLogprob(token=' these', bytes=[32, 116, 104, 101, 115, 101], logprob=-7.5636067), TopLogprob(token=' \"', bytes=[32, 34], logprob=-8.126107), TopLogprob(token=' those', bytes=[32, 116, 104, 111, 115, 101], logprob=-8.251107), TopLogprob(token=' Math', bytes=[32, 77, 97, 116, 104], logprob=-10.813607), TopLogprob(token=' your', bytes=[32, 121, 111, 117, 114], logprob=-13.001107), TopLogprob(token=' our', bytes=[32, 111, 117, 114], logprob=-13.001107), TopLogprob(token=' specified', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 101, 100], logprob=-13.719857)]), ChatCompletionTokenLogprob(token=' categories', bytes=[32, 99, 97, 116, 101, 103, 111, 114, 105, 101, 115], logprob=-0.69576895, top_logprobs=[TopLogprob(token=' categories', bytes=[32, 99, 97, 116, 101, 103, 111, 114, 105, 101, 115], logprob=-0.69576895), TopLogprob(token=' specified', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 101, 100], logprob=-1.320769), TopLogprob(token=' given', bytes=[32, 103, 105, 118, 101, 110], logprob=-1.945769), TopLogprob(token=' provided', bytes=[32, 112, 114, 111, 118, 105, 100, 101, 100], logprob=-3.3207688), TopLogprob(token=' mentioned', bytes=[32, 109, 101, 110, 116, 105, 111, 110, 101, 100], logprob=-3.5707688), TopLogprob(token=' specific', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 99], logprob=-4.820769), TopLogprob(token=' three', bytes=[32, 116, 104, 114, 101, 101], logprob=-5.320769), TopLogprob(token=' listed', bytes=[32, 108, 105, 115, 116, 101, 100], logprob=-5.320769)]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-1.3264381, top_logprobs=[TopLogprob(token='.', bytes=[46], logprob=-1.3264381), TopLogprob(token=' \"', bytes=[32, 34], logprob=-1.3264381), TopLogprob(token=',', bytes=[44], logprob=-1.5764381), TopLogprob(token=' mentioned', bytes=[32, 109, 101, 110, 116, 105, 111, 110, 101, 100], logprob=-2.826438), TopLogprob(token=';', bytes=[59], logprob=-3.076438), TopLogprob(token=':', bytes=[58], logprob=-3.326438), TopLogprob(token=' provided', bytes=[32, 112, 114, 111, 118, 105, 100, 101, 100], logprob=-3.326438), TopLogprob(token=' but', bytes=[32, 98, 117, 116], logprob=-4.076438)])], refusal=None), message=ChatCompletionMessage(content='The input does not appear to be a valid question related to any of the categories.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1729102446, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_6b68a8204b', usage=CompletionUsage(completion_tokens=17, prompt_tokens=109, total_tokens=126, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_to_check_logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty-printed response:\n",
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': {'content': [{'logprob': -2.1731672,\n",
      "                                        'token': 'The',\n",
      "                                        'top_logprobs': [{'logprob': -0.67316717,\n",
      "                                                          'token': 'Science'},\n",
      "                                                         {'logprob': -1.1731672, 'token': 'Math'},\n",
      "                                                         {'logprob': -2.1731672, 'token': 'The'},\n",
      "                                                         {'logprob': -3.6731672, 'token': 'This'},\n",
      "                                                         {'logprob': -3.9231672, 'token': 'None'},\n",
      "                                                         {'logprob': -5.173167, 'token': 'It'},\n",
      "                                                         {'logprob': -5.673167, 'token': 'I'},\n",
      "                                                         {'logprob': -5.923167, 'token': \"I'm\"}]},\n",
      "                                       {'logprob': -1.0813488,\n",
      "                                        'token': ' input',\n",
      "                                        'top_logprobs': [{'logprob': -1.0813488, 'token': ' input'},\n",
      "                                                         {'logprob': -1.7063488, 'token': ' given'},\n",
      "                                                         {'logprob': -1.7063488,\n",
      "                                                          'token': ' question'},\n",
      "                                                         {'logprob': -1.9563488,\n",
      "                                                          'token': ' provided'},\n",
      "                                                         {'logprob': -2.456349, 'token': ' text'},\n",
      "                                                         {'logprob': -3.456349, 'token': ' prompt'},\n",
      "                                                         {'logprob': -3.706349,\n",
      "                                                          'token': ' content'},\n",
      "                                                         {'logprob': -5.331349,\n",
      "                                                          'token': ' statement'}]},\n",
      "                                       {'logprob': -1.8378587,\n",
      "                                        'token': ' does',\n",
      "                                        'top_logprobs': [{'logprob': -0.5878586,\n",
      "                                                          'token': ' provided'},\n",
      "                                                         {'logprob': -1.8378587, 'token': ' does'},\n",
      "                                                         {'logprob': -2.0878587,\n",
      "                                                          'token': ' appears'},\n",
      "                                                         {'logprob': -3.0878587, 'token': ' seems'},\n",
      "                                                         {'logprob': -3.3378587, 'token': ' is'},\n",
      "                                                         {'logprob': -3.3378587, 'token': ' given'},\n",
      "                                                         {'logprob': -3.9628587,\n",
      "                                                          'token': \" doesn't\"},\n",
      "                                                         {'logprob': -4.4628587, 'token': ' you'}]},\n",
      "                                       {'logprob': -2.220075e-06,\n",
      "                                        'token': ' not',\n",
      "                                        'top_logprobs': [{'logprob': -2.220075e-06,\n",
      "                                                          'token': ' not'},\n",
      "                                                         {'logprob': -13.875002,\n",
      "                                                          'token': ' appear'},\n",
      "                                                         {'logprob': -15.000002, 'token': ' seem'},\n",
      "                                                         {'logprob': -15.250002, 'token': ' **'},\n",
      "                                                         {'logprob': -15.875002, 'token': 'not'},\n",
      "                                                         {'logprob': -16.375002, 'token': \"'t\"},\n",
      "                                                         {'logprob': -16.875002, 'token': ' no'},\n",
      "                                                         {'logprob': -17.000002, 'token': \"n't\"}]},\n",
      "                                       {'logprob': -0.8023535,\n",
      "                                        'token': ' appear',\n",
      "                                        'top_logprobs': [{'logprob': -0.8023535,\n",
      "                                                          'token': ' appear'},\n",
      "                                                         {'logprob': -1.6773535,\n",
      "                                                          'token': ' contain'},\n",
      "                                                         {'logprob': -2.1773534, 'token': ' seem'},\n",
      "                                                         {'logprob': -2.4273534,\n",
      "                                                          'token': ' resemble'},\n",
      "                                                         {'logprob': -2.9273534,\n",
      "                                                          'token': ' represent'},\n",
      "                                                         {'logprob': -3.5523534, 'token': ' form'},\n",
      "                                                         {'logprob': -3.6773534,\n",
      "                                                          'token': ' provide'},\n",
      "                                                         {'logprob': -4.4273534,\n",
      "                                                          'token': ' present'}]},\n",
      "                                       {'logprob': -0.005310012,\n",
      "                                        'token': ' to',\n",
      "                                        'top_logprobs': [{'logprob': -0.005310012, 'token': ' to'},\n",
      "                                                         {'logprob': -5.25531, 'token': ' as'},\n",
      "                                                         {'logprob': -10.75531, 'token': ' in'},\n",
      "                                                         {'logprob': -11.13031, 'token': ' like'},\n",
      "                                                         {'logprob': -11.88031,\n",
      "                                                          'token': ' related'},\n",
      "                                                         {'logprob': -11.88031,\n",
      "                                                          'token': ' directly'},\n",
      "                                                         {'logprob': -12.13031,\n",
      "                                                          'token': ' relevant'},\n",
      "                                                         {'logprob': -12.25531,\n",
      "                                                          'token': ' formatted'}]},\n",
      "                                       {'logprob': -0.018437408,\n",
      "                                        'token': ' be',\n",
      "                                        'top_logprobs': [{'logprob': -0.018437408, 'token': ' be'},\n",
      "                                                         {'logprob': -4.2684374,\n",
      "                                                          'token': ' contain'},\n",
      "                                                         {'logprob': -6.6434374,\n",
      "                                                          'token': ' represent'},\n",
      "                                                         {'logprob': -6.8934374, 'token': ' form'},\n",
      "                                                         {'logprob': -8.143437,\n",
      "                                                          'token': ' resemble'},\n",
      "                                                         {'logprob': -8.268437,\n",
      "                                                          'token': ' correspond'},\n",
      "                                                         {'logprob': -8.393437,\n",
      "                                                          'token': ' include'},\n",
      "                                                         {'logprob': -8.768437,\n",
      "                                                          'token': ' present'}]},\n",
      "                                       {'logprob': -0.01343597,\n",
      "                                        'token': ' a',\n",
      "                                        'top_logprobs': [{'logprob': -0.01343597, 'token': ' a'},\n",
      "                                                         {'logprob': -4.638436, 'token': ' an'},\n",
      "                                                         {'logprob': -5.888436, 'token': ' in'},\n",
      "                                                         {'logprob': -8.263436,\n",
      "                                                          'token': ' formatted'},\n",
      "                                                         {'logprob': -9.013436,\n",
      "                                                          'token': ' formulated'},\n",
      "                                                         {'logprob': -9.513436,\n",
      "                                                          'token': ' related'},\n",
      "                                                         {'logprob': -9.763436, 'token': ' phr'},\n",
      "                                                         {'logprob': -9.888436,\n",
      "                                                          'token': ' structured'}]},\n",
      "                                       {'logprob': -1.1622796,\n",
      "                                        'token': ' valid',\n",
      "                                        'top_logprobs': [{'logprob': -1.1622796, 'token': ' valid'},\n",
      "                                                         {'logprob': -1.1622796,\n",
      "                                                          'token': ' question'},\n",
      "                                                         {'logprob': -2.4122796, 'token': ' clear'},\n",
      "                                                         {'logprob': -2.5372796,\n",
      "                                                          'token': ' coherent'},\n",
      "                                                         {'logprob': -2.6622796,\n",
      "                                                          'token': ' typical'},\n",
      "                                                         {'logprob': -3.6622796,\n",
      "                                                          'token': ' recognizable'},\n",
      "                                                         {'logprob': -4.0372796,\n",
      "                                                          'token': ' standard'},\n",
      "                                                         {'logprob': -4.4122796,\n",
      "                                                          'token': ' proper'}]},\n",
      "                                       {'logprob': -0.0461531,\n",
      "                                        'token': ' question',\n",
      "                                        'top_logprobs': [{'logprob': -0.0461531,\n",
      "                                                          'token': ' question'},\n",
      "                                                         {'logprob': -3.421153, 'token': ' or'},\n",
      "                                                         {'logprob': -5.046153, 'token': ','},\n",
      "                                                         {'logprob': -6.171153,\n",
      "                                                          'token': ' natural'},\n",
      "                                                         {'logprob': -6.421153, 'token': ' human'},\n",
      "                                                         {'logprob': -8.296153, 'token': 'ly'},\n",
      "                                                         {'logprob': -8.796153, 'token': ' user'},\n",
      "                                                         {'logprob': -8.921153,\n",
      "                                                          'token': ' class'}]},\n",
      "                                       {'logprob': -1.3656905,\n",
      "                                        'token': ' related',\n",
      "                                        'top_logprobs': [{'logprob': -1.3656905,\n",
      "                                                          'token': ' related'},\n",
      "                                                         {'logprob': -1.8656905, 'token': ','},\n",
      "                                                         {'logprob': -1.8656905, 'token': ' that'},\n",
      "                                                         {'logprob': -2.6156905, 'token': ' in'},\n",
      "                                                         {'logprob': -2.6156905, 'token': ' but'},\n",
      "                                                         {'logprob': -3.1156905, 'token': ' for'},\n",
      "                                                         {'logprob': -3.1156905, 'token': ' from'},\n",
      "                                                         {'logprob': -3.2406905, 'token': '.'}]},\n",
      "                                       {'logprob': -0.0007904516,\n",
      "                                        'token': ' to',\n",
      "                                        'top_logprobs': [{'logprob': -0.0007904516, 'token': ' to'},\n",
      "                                                         {'logprob': -7.3757906,\n",
      "                                                          'token': ' directly'},\n",
      "                                                         {'logprob': -9.125791,\n",
      "                                                          'token': ' specifically'},\n",
      "                                                         {'logprob': -10.250791,\n",
      "                                                          'token': ' explicitly'},\n",
      "                                                         {'logprob': -11.625791,\n",
      "                                                          'token': ' clearly'},\n",
      "                                                         {'logprob': -12.750791,\n",
      "                                                          'token': ' strictly'},\n",
      "                                                         {'logprob': -13.750791, 'token': ' any'},\n",
      "                                                         {'logprob': -14.125791,\n",
      "                                                          'token': ' content'}]},\n",
      "                                       {'logprob': -0.7639222,\n",
      "                                        'token': ' any',\n",
      "                                        'top_logprobs': [{'logprob': -0.7639222, 'token': ' any'},\n",
      "                                                         {'logprob': -1.3889222, 'token': ' \"'},\n",
      "                                                         {'logprob': -1.8889222, 'token': ' the'},\n",
      "                                                         {'logprob': -2.2639222, 'token': ' Math'},\n",
      "                                                         {'logprob': -4.013922, 'token': ' a'},\n",
      "                                                         {'logprob': -4.888922, 'token': ' one'},\n",
      "                                                         {'logprob': -6.763922,\n",
      "                                                          'token': ' specific'},\n",
      "                                                         {'logprob': -6.763922, 'token': ' math'}]},\n",
      "                                       {'logprob': -0.271632,\n",
      "                                        'token': ' of',\n",
      "                                        'top_logprobs': [{'logprob': -0.271632, 'token': ' of'},\n",
      "                                                         {'logprob': -2.021632,\n",
      "                                                          'token': ' category'},\n",
      "                                                         {'logprob': -2.521632,\n",
      "                                                          'token': ' specific'},\n",
      "                                                         {'logprob': -5.521632,\n",
      "                                                          'token': ' subject'},\n",
      "                                                         {'logprob': -5.521632, 'token': ' known'},\n",
      "                                                         {'logprob': -6.021632,\n",
      "                                                          'token': ' specified'},\n",
      "                                                         {'logprob': -6.396632,\n",
      "                                                          'token': ' academic'},\n",
      "                                                         {'logprob': -6.646632,\n",
      "                                                          'token': ' particular'}]},\n",
      "                                       {'logprob': -0.0011067559,\n",
      "                                        'token': ' the',\n",
      "                                        'top_logprobs': [{'logprob': -0.0011067559,\n",
      "                                                          'token': ' the'},\n",
      "                                                         {'logprob': -7.5636067, 'token': ' these'},\n",
      "                                                         {'logprob': -8.126107, 'token': ' \"'},\n",
      "                                                         {'logprob': -8.251107, 'token': ' those'},\n",
      "                                                         {'logprob': -10.813607, 'token': ' Math'},\n",
      "                                                         {'logprob': -13.001107, 'token': ' your'},\n",
      "                                                         {'logprob': -13.001107, 'token': ' our'},\n",
      "                                                         {'logprob': -13.719857,\n",
      "                                                          'token': ' specified'}]},\n",
      "                                       {'logprob': -0.69576895,\n",
      "                                        'token': ' categories',\n",
      "                                        'top_logprobs': [{'logprob': -0.69576895,\n",
      "                                                          'token': ' categories'},\n",
      "                                                         {'logprob': -1.320769,\n",
      "                                                          'token': ' specified'},\n",
      "                                                         {'logprob': -1.945769, 'token': ' given'},\n",
      "                                                         {'logprob': -3.3207688,\n",
      "                                                          'token': ' provided'},\n",
      "                                                         {'logprob': -3.5707688,\n",
      "                                                          'token': ' mentioned'},\n",
      "                                                         {'logprob': -4.820769,\n",
      "                                                          'token': ' specific'},\n",
      "                                                         {'logprob': -5.320769, 'token': ' three'},\n",
      "                                                         {'logprob': -5.320769,\n",
      "                                                          'token': ' listed'}]},\n",
      "                                       {'logprob': -1.3264381,\n",
      "                                        'token': '.',\n",
      "                                        'top_logprobs': [{'logprob': -1.3264381, 'token': '.'},\n",
      "                                                         {'logprob': -1.3264381, 'token': ' \"'},\n",
      "                                                         {'logprob': -1.5764381, 'token': ','},\n",
      "                                                         {'logprob': -2.826438,\n",
      "                                                          'token': ' mentioned'},\n",
      "                                                         {'logprob': -3.076438, 'token': ';'},\n",
      "                                                         {'logprob': -3.326438, 'token': ':'},\n",
      "                                                         {'logprob': -3.326438,\n",
      "                                                          'token': ' provided'},\n",
      "                                                         {'logprob': -4.076438,\n",
      "                                                          'token': ' but'}]}]},\n",
      "              'message': {'content': 'The input does not appear to be a valid question related to '\n",
      "                                     'any of the categories.',\n",
      "                          'role': 'assistant'}}],\n",
      " 'id': 'chatcmpl-AJ2p4RBd8EGPeFlPPPu74nsIuq63k',\n",
      " 'model': 'gpt-4o-2024-08-06',\n",
      " 'usage': {'completion_tokens': 17, 'prompt_tokens': 109, 'total_tokens': 126}}\n",
      "\n",
      "JSON formatted response:\n",
      "{\n",
      "  \"id\": \"chatcmpl-AJ2p4RBd8EGPeFlPPPu74nsIuq63k\",\n",
      "  \"model\": \"gpt-4o-2024-08-06\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"The input does not appear to be a valid question related to any of the categories.\",\n",
      "        \"role\": \"assistant\"\n",
      "      },\n",
      "      \"logprobs\": {\n",
      "        \"content\": [\n",
      "          {\n",
      "            \"token\": \"The\",\n",
      "            \"logprob\": -2.1731672,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \"Science\",\n",
      "                \"logprob\": -0.67316717\n",
      "              },\n",
      "              {\n",
      "                \"token\": \"Math\",\n",
      "                \"logprob\": -1.1731672\n",
      "              },\n",
      "              {\n",
      "                \"token\": \"The\",\n",
      "                \"logprob\": -2.1731672\n",
      "              },\n",
      "              {\n",
      "                \"token\": \"This\",\n",
      "                \"logprob\": -3.6731672\n",
      "              },\n",
      "              {\n",
      "                \"token\": \"None\",\n",
      "                \"logprob\": -3.9231672\n",
      "              },\n",
      "              {\n",
      "                \"token\": \"It\",\n",
      "                \"logprob\": -5.173167\n",
      "              },\n",
      "              {\n",
      "                \"token\": \"I\",\n",
      "                \"logprob\": -5.673167\n",
      "              },\n",
      "              {\n",
      "                \"token\": \"I'm\",\n",
      "                \"logprob\": -5.923167\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" input\",\n",
      "            \"logprob\": -1.0813488,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" input\",\n",
      "                \"logprob\": -1.0813488\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" given\",\n",
      "                \"logprob\": -1.7063488\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" question\",\n",
      "                \"logprob\": -1.7063488\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" provided\",\n",
      "                \"logprob\": -1.9563488\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" text\",\n",
      "                \"logprob\": -2.456349\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" prompt\",\n",
      "                \"logprob\": -3.456349\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" content\",\n",
      "                \"logprob\": -3.706349\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" statement\",\n",
      "                \"logprob\": -5.331349\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" does\",\n",
      "            \"logprob\": -1.8378587,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" provided\",\n",
      "                \"logprob\": -0.5878586\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" does\",\n",
      "                \"logprob\": -1.8378587\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" appears\",\n",
      "                \"logprob\": -2.0878587\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" seems\",\n",
      "                \"logprob\": -3.0878587\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" is\",\n",
      "                \"logprob\": -3.3378587\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" given\",\n",
      "                \"logprob\": -3.3378587\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" doesn't\",\n",
      "                \"logprob\": -3.9628587\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" you\",\n",
      "                \"logprob\": -4.4628587\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" not\",\n",
      "            \"logprob\": -2.220075e-06,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" not\",\n",
      "                \"logprob\": -2.220075e-06\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" appear\",\n",
      "                \"logprob\": -13.875002\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" seem\",\n",
      "                \"logprob\": -15.000002\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" **\",\n",
      "                \"logprob\": -15.250002\n",
      "              },\n",
      "              {\n",
      "                \"token\": \"not\",\n",
      "                \"logprob\": -15.875002\n",
      "              },\n",
      "              {\n",
      "                \"token\": \"'t\",\n",
      "                \"logprob\": -16.375002\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" no\",\n",
      "                \"logprob\": -16.875002\n",
      "              },\n",
      "              {\n",
      "                \"token\": \"n't\",\n",
      "                \"logprob\": -17.000002\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" appear\",\n",
      "            \"logprob\": -0.8023535,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" appear\",\n",
      "                \"logprob\": -0.8023535\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" contain\",\n",
      "                \"logprob\": -1.6773535\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" seem\",\n",
      "                \"logprob\": -2.1773534\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" resemble\",\n",
      "                \"logprob\": -2.4273534\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" represent\",\n",
      "                \"logprob\": -2.9273534\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" form\",\n",
      "                \"logprob\": -3.5523534\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" provide\",\n",
      "                \"logprob\": -3.6773534\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" present\",\n",
      "                \"logprob\": -4.4273534\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" to\",\n",
      "            \"logprob\": -0.005310012,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" to\",\n",
      "                \"logprob\": -0.005310012\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" as\",\n",
      "                \"logprob\": -5.25531\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" in\",\n",
      "                \"logprob\": -10.75531\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" like\",\n",
      "                \"logprob\": -11.13031\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" related\",\n",
      "                \"logprob\": -11.88031\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" directly\",\n",
      "                \"logprob\": -11.88031\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" relevant\",\n",
      "                \"logprob\": -12.13031\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" formatted\",\n",
      "                \"logprob\": -12.25531\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" be\",\n",
      "            \"logprob\": -0.018437408,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" be\",\n",
      "                \"logprob\": -0.018437408\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" contain\",\n",
      "                \"logprob\": -4.2684374\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" represent\",\n",
      "                \"logprob\": -6.6434374\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" form\",\n",
      "                \"logprob\": -6.8934374\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" resemble\",\n",
      "                \"logprob\": -8.143437\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" correspond\",\n",
      "                \"logprob\": -8.268437\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" include\",\n",
      "                \"logprob\": -8.393437\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" present\",\n",
      "                \"logprob\": -8.768437\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" a\",\n",
      "            \"logprob\": -0.01343597,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" a\",\n",
      "                \"logprob\": -0.01343597\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" an\",\n",
      "                \"logprob\": -4.638436\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" in\",\n",
      "                \"logprob\": -5.888436\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" formatted\",\n",
      "                \"logprob\": -8.263436\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" formulated\",\n",
      "                \"logprob\": -9.013436\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" related\",\n",
      "                \"logprob\": -9.513436\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" phr\",\n",
      "                \"logprob\": -9.763436\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" structured\",\n",
      "                \"logprob\": -9.888436\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" valid\",\n",
      "            \"logprob\": -1.1622796,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" valid\",\n",
      "                \"logprob\": -1.1622796\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" question\",\n",
      "                \"logprob\": -1.1622796\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" clear\",\n",
      "                \"logprob\": -2.4122796\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" coherent\",\n",
      "                \"logprob\": -2.5372796\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" typical\",\n",
      "                \"logprob\": -2.6622796\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" recognizable\",\n",
      "                \"logprob\": -3.6622796\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" standard\",\n",
      "                \"logprob\": -4.0372796\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" proper\",\n",
      "                \"logprob\": -4.4122796\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" question\",\n",
      "            \"logprob\": -0.0461531,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" question\",\n",
      "                \"logprob\": -0.0461531\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" or\",\n",
      "                \"logprob\": -3.421153\n",
      "              },\n",
      "              {\n",
      "                \"token\": \",\",\n",
      "                \"logprob\": -5.046153\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" natural\",\n",
      "                \"logprob\": -6.171153\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" human\",\n",
      "                \"logprob\": -6.421153\n",
      "              },\n",
      "              {\n",
      "                \"token\": \"ly\",\n",
      "                \"logprob\": -8.296153\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" user\",\n",
      "                \"logprob\": -8.796153\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" class\",\n",
      "                \"logprob\": -8.921153\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" related\",\n",
      "            \"logprob\": -1.3656905,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" related\",\n",
      "                \"logprob\": -1.3656905\n",
      "              },\n",
      "              {\n",
      "                \"token\": \",\",\n",
      "                \"logprob\": -1.8656905\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" that\",\n",
      "                \"logprob\": -1.8656905\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" in\",\n",
      "                \"logprob\": -2.6156905\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" but\",\n",
      "                \"logprob\": -2.6156905\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" for\",\n",
      "                \"logprob\": -3.1156905\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" from\",\n",
      "                \"logprob\": -3.1156905\n",
      "              },\n",
      "              {\n",
      "                \"token\": \".\",\n",
      "                \"logprob\": -3.2406905\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" to\",\n",
      "            \"logprob\": -0.0007904516,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" to\",\n",
      "                \"logprob\": -0.0007904516\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" directly\",\n",
      "                \"logprob\": -7.3757906\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" specifically\",\n",
      "                \"logprob\": -9.125791\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" explicitly\",\n",
      "                \"logprob\": -10.250791\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" clearly\",\n",
      "                \"logprob\": -11.625791\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" strictly\",\n",
      "                \"logprob\": -12.750791\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" any\",\n",
      "                \"logprob\": -13.750791\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" content\",\n",
      "                \"logprob\": -14.125791\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" any\",\n",
      "            \"logprob\": -0.7639222,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" any\",\n",
      "                \"logprob\": -0.7639222\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" \\\"\",\n",
      "                \"logprob\": -1.3889222\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" the\",\n",
      "                \"logprob\": -1.8889222\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" Math\",\n",
      "                \"logprob\": -2.2639222\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" a\",\n",
      "                \"logprob\": -4.013922\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" one\",\n",
      "                \"logprob\": -4.888922\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" specific\",\n",
      "                \"logprob\": -6.763922\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" math\",\n",
      "                \"logprob\": -6.763922\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" of\",\n",
      "            \"logprob\": -0.271632,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" of\",\n",
      "                \"logprob\": -0.271632\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" category\",\n",
      "                \"logprob\": -2.021632\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" specific\",\n",
      "                \"logprob\": -2.521632\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" subject\",\n",
      "                \"logprob\": -5.521632\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" known\",\n",
      "                \"logprob\": -5.521632\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" specified\",\n",
      "                \"logprob\": -6.021632\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" academic\",\n",
      "                \"logprob\": -6.396632\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" particular\",\n",
      "                \"logprob\": -6.646632\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" the\",\n",
      "            \"logprob\": -0.0011067559,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" the\",\n",
      "                \"logprob\": -0.0011067559\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" these\",\n",
      "                \"logprob\": -7.5636067\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" \\\"\",\n",
      "                \"logprob\": -8.126107\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" those\",\n",
      "                \"logprob\": -8.251107\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" Math\",\n",
      "                \"logprob\": -10.813607\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" your\",\n",
      "                \"logprob\": -13.001107\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" our\",\n",
      "                \"logprob\": -13.001107\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" specified\",\n",
      "                \"logprob\": -13.719857\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \" categories\",\n",
      "            \"logprob\": -0.69576895,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \" categories\",\n",
      "                \"logprob\": -0.69576895\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" specified\",\n",
      "                \"logprob\": -1.320769\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" given\",\n",
      "                \"logprob\": -1.945769\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" provided\",\n",
      "                \"logprob\": -3.3207688\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" mentioned\",\n",
      "                \"logprob\": -3.5707688\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" specific\",\n",
      "                \"logprob\": -4.820769\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" three\",\n",
      "                \"logprob\": -5.320769\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" listed\",\n",
      "                \"logprob\": -5.320769\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"token\": \".\",\n",
      "            \"logprob\": -1.3264381,\n",
      "            \"top_logprobs\": [\n",
      "              {\n",
      "                \"token\": \".\",\n",
      "                \"logprob\": -1.3264381\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" \\\"\",\n",
      "                \"logprob\": -1.3264381\n",
      "              },\n",
      "              {\n",
      "                \"token\": \",\",\n",
      "                \"logprob\": -1.5764381\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" mentioned\",\n",
      "                \"logprob\": -2.826438\n",
      "              },\n",
      "              {\n",
      "                \"token\": \";\",\n",
      "                \"logprob\": -3.076438\n",
      "              },\n",
      "              {\n",
      "                \"token\": \":\",\n",
      "                \"logprob\": -3.326438\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" provided\",\n",
      "                \"logprob\": -3.326438\n",
      "              },\n",
      "              {\n",
      "                \"token\": \" but\",\n",
      "                \"logprob\": -4.076438\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 17,\n",
      "    \"prompt_tokens\": 109,\n",
      "    \"total_tokens\": 126\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "# Extract the relevant information from the response\n",
    "response_data = {\n",
    "    \"id\": response_to_check_logprob.id,\n",
    "    \"model\": response_to_check_logprob.model,\n",
    "    \"choices\": [{\n",
    "        \"finish_reason\": choice.finish_reason,\n",
    "        \"index\": choice.index,\n",
    "        \"message\": {\n",
    "            \"content\": choice.message.content,\n",
    "            \"role\": choice.message.role\n",
    "        },\n",
    "        \"logprobs\": {\n",
    "            \"content\": [{\n",
    "                \"token\": logprob.token,\n",
    "                \"logprob\": logprob.logprob,\n",
    "                \"top_logprobs\": [\n",
    "                    {\"token\": top.token, \"logprob\": top.logprob}\n",
    "                    for top in logprob.top_logprobs\n",
    "                ]\n",
    "            } for logprob in choice.logprobs.content]\n",
    "        }\n",
    "    } for choice in response_to_check_logprob.choices],\n",
    "    \"usage\": {\n",
    "        \"completion_tokens\": response_to_check_logprob.usage.completion_tokens,\n",
    "        \"prompt_tokens\": response_to_check_logprob.usage.prompt_tokens,\n",
    "        \"total_tokens\": response_to_check_logprob.usage.total_tokens\n",
    "    }\n",
    "}\n",
    "\n",
    "# Pretty print the extracted data\n",
    "print(\"Pretty-printed response:\")\n",
    "pprint(response_data, width=100, compact=False)\n",
    "\n",
    "# Additionally, print as formatted JSON for better readability\n",
    "print(\"\\nJSON formatted response:\")\n",
    "print(json.dumps(response_data, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprobs = response_to_check_logprob.choices[0].logprobs.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TopLogprob(token='Science', bytes=[83, 99, 105, 101, 110, 99, 101], logprob=-0.67316717),\n",
       " TopLogprob(token='Math', bytes=[77, 97, 116, 104], logprob=-1.1731672),\n",
       " TopLogprob(token='The', bytes=[84, 104, 101], logprob=-2.1731672),\n",
       " TopLogprob(token='This', bytes=[84, 104, 105, 115], logprob=-3.6731672),\n",
       " TopLogprob(token='None', bytes=[78, 111, 110, 101], logprob=-3.9231672),\n",
       " TopLogprob(token='It', bytes=[73, 116], logprob=-5.173167),\n",
       " TopLogprob(token='I', bytes=[73], logprob=-5.673167),\n",
       " TopLogprob(token=\"I'm\", bytes=[73, 39, 109], logprob=-5.923167)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs[0].top_logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-2.1731672, top_logprobs=[TopLogprob(token='Science', bytes=[83, 99, 105, 101, 110, 99, 101], logprob=-0.67316717), TopLogprob(token='Math', bytes=[77, 97, 116, 104], logprob=-1.1731672), TopLogprob(token='The', bytes=[84, 104, 101], logprob=-2.1731672), TopLogprob(token='This', bytes=[84, 104, 105, 115], logprob=-3.6731672), TopLogprob(token='None', bytes=[78, 111, 110, 101], logprob=-3.9231672), TopLogprob(token='It', bytes=[73, 116], logprob=-5.173167), TopLogprob(token='I', bytes=[73], logprob=-5.673167), TopLogprob(token=\"I'm\", bytes=[73, 39, 109], logprob=-5.923167)]),\n",
       " ChatCompletionTokenLogprob(token=' input', bytes=[32, 105, 110, 112, 117, 116], logprob=-1.0813488, top_logprobs=[TopLogprob(token=' input', bytes=[32, 105, 110, 112, 117, 116], logprob=-1.0813488), TopLogprob(token=' given', bytes=[32, 103, 105, 118, 101, 110], logprob=-1.7063488), TopLogprob(token=' question', bytes=[32, 113, 117, 101, 115, 116, 105, 111, 110], logprob=-1.7063488), TopLogprob(token=' provided', bytes=[32, 112, 114, 111, 118, 105, 100, 101, 100], logprob=-1.9563488), TopLogprob(token=' text', bytes=[32, 116, 101, 120, 116], logprob=-2.456349), TopLogprob(token=' prompt', bytes=[32, 112, 114, 111, 109, 112, 116], logprob=-3.456349), TopLogprob(token=' content', bytes=[32, 99, 111, 110, 116, 101, 110, 116], logprob=-3.706349), TopLogprob(token=' statement', bytes=[32, 115, 116, 97, 116, 101, 109, 101, 110, 116], logprob=-5.331349)]),\n",
       " ChatCompletionTokenLogprob(token=' does', bytes=[32, 100, 111, 101, 115], logprob=-1.8378587, top_logprobs=[TopLogprob(token=' provided', bytes=[32, 112, 114, 111, 118, 105, 100, 101, 100], logprob=-0.5878586), TopLogprob(token=' does', bytes=[32, 100, 111, 101, 115], logprob=-1.8378587), TopLogprob(token=' appears', bytes=[32, 97, 112, 112, 101, 97, 114, 115], logprob=-2.0878587), TopLogprob(token=' seems', bytes=[32, 115, 101, 101, 109, 115], logprob=-3.0878587), TopLogprob(token=' is', bytes=[32, 105, 115], logprob=-3.3378587), TopLogprob(token=' given', bytes=[32, 103, 105, 118, 101, 110], logprob=-3.3378587), TopLogprob(token=\" doesn't\", bytes=[32, 100, 111, 101, 115, 110, 39, 116], logprob=-3.9628587), TopLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-4.4628587)]),\n",
       " ChatCompletionTokenLogprob(token=' not', bytes=[32, 110, 111, 116], logprob=-2.220075e-06, top_logprobs=[TopLogprob(token=' not', bytes=[32, 110, 111, 116], logprob=-2.220075e-06), TopLogprob(token=' appear', bytes=[32, 97, 112, 112, 101, 97, 114], logprob=-13.875002), TopLogprob(token=' seem', bytes=[32, 115, 101, 101, 109], logprob=-15.000002), TopLogprob(token=' **', bytes=[32, 42, 42], logprob=-15.250002), TopLogprob(token='not', bytes=[110, 111, 116], logprob=-15.875002), TopLogprob(token=\"'t\", bytes=[39, 116], logprob=-16.375002), TopLogprob(token=' no', bytes=[32, 110, 111], logprob=-16.875002), TopLogprob(token=\"n't\", bytes=[110, 39, 116], logprob=-17.000002)]),\n",
       " ChatCompletionTokenLogprob(token=' appear', bytes=[32, 97, 112, 112, 101, 97, 114], logprob=-0.8023535, top_logprobs=[TopLogprob(token=' appear', bytes=[32, 97, 112, 112, 101, 97, 114], logprob=-0.8023535), TopLogprob(token=' contain', bytes=[32, 99, 111, 110, 116, 97, 105, 110], logprob=-1.6773535), TopLogprob(token=' seem', bytes=[32, 115, 101, 101, 109], logprob=-2.1773534), TopLogprob(token=' resemble', bytes=[32, 114, 101, 115, 101, 109, 98, 108, 101], logprob=-2.4273534), TopLogprob(token=' represent', bytes=[32, 114, 101, 112, 114, 101, 115, 101, 110, 116], logprob=-2.9273534), TopLogprob(token=' form', bytes=[32, 102, 111, 114, 109], logprob=-3.5523534), TopLogprob(token=' provide', bytes=[32, 112, 114, 111, 118, 105, 100, 101], logprob=-3.6773534), TopLogprob(token=' present', bytes=[32, 112, 114, 101, 115, 101, 110, 116], logprob=-4.4273534)]),\n",
       " ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.005310012, top_logprobs=[TopLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.005310012), TopLogprob(token=' as', bytes=[32, 97, 115], logprob=-5.25531), TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-10.75531), TopLogprob(token=' like', bytes=[32, 108, 105, 107, 101], logprob=-11.13031), TopLogprob(token=' related', bytes=[32, 114, 101, 108, 97, 116, 101, 100], logprob=-11.88031), TopLogprob(token=' directly', bytes=[32, 100, 105, 114, 101, 99, 116, 108, 121], logprob=-11.88031), TopLogprob(token=' relevant', bytes=[32, 114, 101, 108, 101, 118, 97, 110, 116], logprob=-12.13031), TopLogprob(token=' formatted', bytes=[32, 102, 111, 114, 109, 97, 116, 116, 101, 100], logprob=-12.25531)]),\n",
       " ChatCompletionTokenLogprob(token=' be', bytes=[32, 98, 101], logprob=-0.018437408, top_logprobs=[TopLogprob(token=' be', bytes=[32, 98, 101], logprob=-0.018437408), TopLogprob(token=' contain', bytes=[32, 99, 111, 110, 116, 97, 105, 110], logprob=-4.2684374), TopLogprob(token=' represent', bytes=[32, 114, 101, 112, 114, 101, 115, 101, 110, 116], logprob=-6.6434374), TopLogprob(token=' form', bytes=[32, 102, 111, 114, 109], logprob=-6.8934374), TopLogprob(token=' resemble', bytes=[32, 114, 101, 115, 101, 109, 98, 108, 101], logprob=-8.143437), TopLogprob(token=' correspond', bytes=[32, 99, 111, 114, 114, 101, 115, 112, 111, 110, 100], logprob=-8.268437), TopLogprob(token=' include', bytes=[32, 105, 110, 99, 108, 117, 100, 101], logprob=-8.393437), TopLogprob(token=' present', bytes=[32, 112, 114, 101, 115, 101, 110, 116], logprob=-8.768437)]),\n",
       " ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.01343597, top_logprobs=[TopLogprob(token=' a', bytes=[32, 97], logprob=-0.01343597), TopLogprob(token=' an', bytes=[32, 97, 110], logprob=-4.638436), TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-5.888436), TopLogprob(token=' formatted', bytes=[32, 102, 111, 114, 109, 97, 116, 116, 101, 100], logprob=-8.263436), TopLogprob(token=' formulated', bytes=[32, 102, 111, 114, 109, 117, 108, 97, 116, 101, 100], logprob=-9.013436), TopLogprob(token=' related', bytes=[32, 114, 101, 108, 97, 116, 101, 100], logprob=-9.513436), TopLogprob(token=' phr', bytes=[32, 112, 104, 114], logprob=-9.763436), TopLogprob(token=' structured', bytes=[32, 115, 116, 114, 117, 99, 116, 117, 114, 101, 100], logprob=-9.888436)]),\n",
       " ChatCompletionTokenLogprob(token=' valid', bytes=[32, 118, 97, 108, 105, 100], logprob=-1.1622796, top_logprobs=[TopLogprob(token=' valid', bytes=[32, 118, 97, 108, 105, 100], logprob=-1.1622796), TopLogprob(token=' question', bytes=[32, 113, 117, 101, 115, 116, 105, 111, 110], logprob=-1.1622796), TopLogprob(token=' clear', bytes=[32, 99, 108, 101, 97, 114], logprob=-2.4122796), TopLogprob(token=' coherent', bytes=[32, 99, 111, 104, 101, 114, 101, 110, 116], logprob=-2.5372796), TopLogprob(token=' typical', bytes=[32, 116, 121, 112, 105, 99, 97, 108], logprob=-2.6622796), TopLogprob(token=' recognizable', bytes=[32, 114, 101, 99, 111, 103, 110, 105, 122, 97, 98, 108, 101], logprob=-3.6622796), TopLogprob(token=' standard', bytes=[32, 115, 116, 97, 110, 100, 97, 114, 100], logprob=-4.0372796), TopLogprob(token=' proper', bytes=[32, 112, 114, 111, 112, 101, 114], logprob=-4.4122796)]),\n",
       " ChatCompletionTokenLogprob(token=' question', bytes=[32, 113, 117, 101, 115, 116, 105, 111, 110], logprob=-0.0461531, top_logprobs=[TopLogprob(token=' question', bytes=[32, 113, 117, 101, 115, 116, 105, 111, 110], logprob=-0.0461531), TopLogprob(token=' or', bytes=[32, 111, 114], logprob=-3.421153), TopLogprob(token=',', bytes=[44], logprob=-5.046153), TopLogprob(token=' natural', bytes=[32, 110, 97, 116, 117, 114, 97, 108], logprob=-6.171153), TopLogprob(token=' human', bytes=[32, 104, 117, 109, 97, 110], logprob=-6.421153), TopLogprob(token='ly', bytes=[108, 121], logprob=-8.296153), TopLogprob(token=' user', bytes=[32, 117, 115, 101, 114], logprob=-8.796153), TopLogprob(token=' class', bytes=[32, 99, 108, 97, 115, 115], logprob=-8.921153)]),\n",
       " ChatCompletionTokenLogprob(token=' related', bytes=[32, 114, 101, 108, 97, 116, 101, 100], logprob=-1.3656905, top_logprobs=[TopLogprob(token=' related', bytes=[32, 114, 101, 108, 97, 116, 101, 100], logprob=-1.3656905), TopLogprob(token=',', bytes=[44], logprob=-1.8656905), TopLogprob(token=' that', bytes=[32, 116, 104, 97, 116], logprob=-1.8656905), TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-2.6156905), TopLogprob(token=' but', bytes=[32, 98, 117, 116], logprob=-2.6156905), TopLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-3.1156905), TopLogprob(token=' from', bytes=[32, 102, 114, 111, 109], logprob=-3.1156905), TopLogprob(token='.', bytes=[46], logprob=-3.2406905)]),\n",
       " ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.0007904516, top_logprobs=[TopLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.0007904516), TopLogprob(token=' directly', bytes=[32, 100, 105, 114, 101, 99, 116, 108, 121], logprob=-7.3757906), TopLogprob(token=' specifically', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 99, 97, 108, 108, 121], logprob=-9.125791), TopLogprob(token=' explicitly', bytes=[32, 101, 120, 112, 108, 105, 99, 105, 116, 108, 121], logprob=-10.250791), TopLogprob(token=' clearly', bytes=[32, 99, 108, 101, 97, 114, 108, 121], logprob=-11.625791), TopLogprob(token=' strictly', bytes=[32, 115, 116, 114, 105, 99, 116, 108, 121], logprob=-12.750791), TopLogprob(token=' any', bytes=[32, 97, 110, 121], logprob=-13.750791), TopLogprob(token=' content', bytes=[32, 99, 111, 110, 116, 101, 110, 116], logprob=-14.125791)]),\n",
       " ChatCompletionTokenLogprob(token=' any', bytes=[32, 97, 110, 121], logprob=-0.7639222, top_logprobs=[TopLogprob(token=' any', bytes=[32, 97, 110, 121], logprob=-0.7639222), TopLogprob(token=' \"', bytes=[32, 34], logprob=-1.3889222), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-1.8889222), TopLogprob(token=' Math', bytes=[32, 77, 97, 116, 104], logprob=-2.2639222), TopLogprob(token=' a', bytes=[32, 97], logprob=-4.013922), TopLogprob(token=' one', bytes=[32, 111, 110, 101], logprob=-4.888922), TopLogprob(token=' specific', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 99], logprob=-6.763922), TopLogprob(token=' math', bytes=[32, 109, 97, 116, 104], logprob=-6.763922)]),\n",
       " ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.271632, top_logprobs=[TopLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.271632), TopLogprob(token=' category', bytes=[32, 99, 97, 116, 101, 103, 111, 114, 121], logprob=-2.021632), TopLogprob(token=' specific', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 99], logprob=-2.521632), TopLogprob(token=' subject', bytes=[32, 115, 117, 98, 106, 101, 99, 116], logprob=-5.521632), TopLogprob(token=' known', bytes=[32, 107, 110, 111, 119, 110], logprob=-5.521632), TopLogprob(token=' specified', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 101, 100], logprob=-6.021632), TopLogprob(token=' academic', bytes=[32, 97, 99, 97, 100, 101, 109, 105, 99], logprob=-6.396632), TopLogprob(token=' particular', bytes=[32, 112, 97, 114, 116, 105, 99, 117, 108, 97, 114], logprob=-6.646632)]),\n",
       " ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.0011067559, top_logprobs=[TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.0011067559), TopLogprob(token=' these', bytes=[32, 116, 104, 101, 115, 101], logprob=-7.5636067), TopLogprob(token=' \"', bytes=[32, 34], logprob=-8.126107), TopLogprob(token=' those', bytes=[32, 116, 104, 111, 115, 101], logprob=-8.251107), TopLogprob(token=' Math', bytes=[32, 77, 97, 116, 104], logprob=-10.813607), TopLogprob(token=' your', bytes=[32, 121, 111, 117, 114], logprob=-13.001107), TopLogprob(token=' our', bytes=[32, 111, 117, 114], logprob=-13.001107), TopLogprob(token=' specified', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 101, 100], logprob=-13.719857)]),\n",
       " ChatCompletionTokenLogprob(token=' categories', bytes=[32, 99, 97, 116, 101, 103, 111, 114, 105, 101, 115], logprob=-0.69576895, top_logprobs=[TopLogprob(token=' categories', bytes=[32, 99, 97, 116, 101, 103, 111, 114, 105, 101, 115], logprob=-0.69576895), TopLogprob(token=' specified', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 101, 100], logprob=-1.320769), TopLogprob(token=' given', bytes=[32, 103, 105, 118, 101, 110], logprob=-1.945769), TopLogprob(token=' provided', bytes=[32, 112, 114, 111, 118, 105, 100, 101, 100], logprob=-3.3207688), TopLogprob(token=' mentioned', bytes=[32, 109, 101, 110, 116, 105, 111, 110, 101, 100], logprob=-3.5707688), TopLogprob(token=' specific', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 99], logprob=-4.820769), TopLogprob(token=' three', bytes=[32, 116, 104, 114, 101, 101], logprob=-5.320769), TopLogprob(token=' listed', bytes=[32, 108, 105, 115, 116, 101, 100], logprob=-5.320769)]),\n",
       " ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-1.3264381, top_logprobs=[TopLogprob(token='.', bytes=[46], logprob=-1.3264381), TopLogprob(token=' \"', bytes=[32, 34], logprob=-1.3264381), TopLogprob(token=',', bytes=[44], logprob=-1.5764381), TopLogprob(token=' mentioned', bytes=[32, 109, 101, 110, 116, 105, 111, 110, 101, 100], logprob=-2.826438), TopLogprob(token=';', bytes=[59], logprob=-3.076438), TopLogprob(token=':', bytes=[58], logprob=-3.326438), TopLogprob(token=' provided', bytes=[32, 112, 114, 111, 118, 105, 100, 101, 100], logprob=-3.326438), TopLogprob(token=' but', bytes=[32, 98, 117, 116], logprob=-4.076438)])]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TopLogprob(token='Science', bytes=[83, 99, 105, 101, 110, 99, 101], logprob=-0.67316717), TopLogprob(token='Math', bytes=[77, 97, 116, 104], logprob=-1.1731672), TopLogprob(token='The', bytes=[84, 104, 101], logprob=-2.1731672), TopLogprob(token='This', bytes=[84, 104, 105, 115], logprob=-3.6731672), TopLogprob(token='None', bytes=[78, 111, 110, 101], logprob=-3.9231672), TopLogprob(token='It', bytes=[73, 116], logprob=-5.173167), TopLogprob(token='I', bytes=[73], logprob=-5.673167), TopLogprob(token=\"I'm\", bytes=[73, 39, 109], logprob=-5.923167)]\n",
      "\n",
      "Science\n",
      "-0.67316717\n",
      "\n",
      "TopLogprob(token='Science', bytes=[83, 99, 105, 101, 110, 99, 101], logprob=-0.67316717)\n",
      "\n",
      "Math\n",
      "-1.1731672\n",
      "\n",
      "TopLogprob(token='Math', bytes=[77, 97, 116, 104], logprob=-1.1731672)\n",
      "\n",
      "The\n",
      "-2.1731672\n",
      "\n",
      "TopLogprob(token='The', bytes=[84, 104, 101], logprob=-2.1731672)\n",
      "\n",
      "This\n",
      "-3.6731672\n",
      "\n",
      "TopLogprob(token='This', bytes=[84, 104, 105, 115], logprob=-3.6731672)\n",
      "\n",
      "None\n",
      "-3.9231672\n",
      "\n",
      "TopLogprob(token='None', bytes=[78, 111, 110, 101], logprob=-3.9231672)\n",
      "\n",
      "It\n",
      "-5.173167\n",
      "\n",
      "TopLogprob(token='It', bytes=[73, 116], logprob=-5.173167)\n",
      "\n",
      "I\n",
      "-5.673167\n",
      "\n",
      "TopLogprob(token='I', bytes=[73], logprob=-5.673167)\n",
      "\n",
      "I'm\n",
      "-5.923167\n",
      "\n",
      "TopLogprob(token=\"I'm\", bytes=[73, 39, 109], logprob=-5.923167)\n",
      "\n",
      "[TopLogprob(token=' input', bytes=[32, 105, 110, 112, 117, 116], logprob=-1.0813488), TopLogprob(token=' given', bytes=[32, 103, 105, 118, 101, 110], logprob=-1.7063488), TopLogprob(token=' question', bytes=[32, 113, 117, 101, 115, 116, 105, 111, 110], logprob=-1.7063488), TopLogprob(token=' provided', bytes=[32, 112, 114, 111, 118, 105, 100, 101, 100], logprob=-1.9563488), TopLogprob(token=' text', bytes=[32, 116, 101, 120, 116], logprob=-2.456349), TopLogprob(token=' prompt', bytes=[32, 112, 114, 111, 109, 112, 116], logprob=-3.456349), TopLogprob(token=' content', bytes=[32, 99, 111, 110, 116, 101, 110, 116], logprob=-3.706349), TopLogprob(token=' statement', bytes=[32, 115, 116, 97, 116, 101, 109, 101, 110, 116], logprob=-5.331349)]\n",
      "\n",
      " input\n",
      "-1.0813488\n",
      "\n",
      "TopLogprob(token=' input', bytes=[32, 105, 110, 112, 117, 116], logprob=-1.0813488)\n",
      "\n",
      " given\n",
      "-1.7063488\n",
      "\n",
      "TopLogprob(token=' given', bytes=[32, 103, 105, 118, 101, 110], logprob=-1.7063488)\n",
      "\n",
      " question\n",
      "-1.7063488\n",
      "\n",
      "TopLogprob(token=' question', bytes=[32, 113, 117, 101, 115, 116, 105, 111, 110], logprob=-1.7063488)\n",
      "\n",
      " provided\n",
      "-1.9563488\n",
      "\n",
      "TopLogprob(token=' provided', bytes=[32, 112, 114, 111, 118, 105, 100, 101, 100], logprob=-1.9563488)\n",
      "\n",
      " text\n",
      "-2.456349\n",
      "\n",
      "TopLogprob(token=' text', bytes=[32, 116, 101, 120, 116], logprob=-2.456349)\n",
      "\n",
      " prompt\n",
      "-3.456349\n",
      "\n",
      "TopLogprob(token=' prompt', bytes=[32, 112, 114, 111, 109, 112, 116], logprob=-3.456349)\n",
      "\n",
      " content\n",
      "-3.706349\n",
      "\n",
      "TopLogprob(token=' content', bytes=[32, 99, 111, 110, 116, 101, 110, 116], logprob=-3.706349)\n",
      "\n",
      " statement\n",
      "-5.331349\n",
      "\n",
      "TopLogprob(token=' statement', bytes=[32, 115, 116, 97, 116, 101, 109, 101, 110, 116], logprob=-5.331349)\n",
      "\n",
      "[TopLogprob(token=' provided', bytes=[32, 112, 114, 111, 118, 105, 100, 101, 100], logprob=-0.5878586), TopLogprob(token=' does', bytes=[32, 100, 111, 101, 115], logprob=-1.8378587), TopLogprob(token=' appears', bytes=[32, 97, 112, 112, 101, 97, 114, 115], logprob=-2.0878587), TopLogprob(token=' seems', bytes=[32, 115, 101, 101, 109, 115], logprob=-3.0878587), TopLogprob(token=' is', bytes=[32, 105, 115], logprob=-3.3378587), TopLogprob(token=' given', bytes=[32, 103, 105, 118, 101, 110], logprob=-3.3378587), TopLogprob(token=\" doesn't\", bytes=[32, 100, 111, 101, 115, 110, 39, 116], logprob=-3.9628587), TopLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-4.4628587)]\n",
      "\n",
      " provided\n",
      "-0.5878586\n",
      "\n",
      "TopLogprob(token=' provided', bytes=[32, 112, 114, 111, 118, 105, 100, 101, 100], logprob=-0.5878586)\n",
      "\n",
      " does\n",
      "-1.8378587\n",
      "\n",
      "TopLogprob(token=' does', bytes=[32, 100, 111, 101, 115], logprob=-1.8378587)\n",
      "\n",
      " appears\n",
      "-2.0878587\n",
      "\n",
      "TopLogprob(token=' appears', bytes=[32, 97, 112, 112, 101, 97, 114, 115], logprob=-2.0878587)\n",
      "\n",
      " seems\n",
      "-3.0878587\n",
      "\n",
      "TopLogprob(token=' seems', bytes=[32, 115, 101, 101, 109, 115], logprob=-3.0878587)\n",
      "\n",
      " is\n",
      "-3.3378587\n",
      "\n",
      "TopLogprob(token=' is', bytes=[32, 105, 115], logprob=-3.3378587)\n",
      "\n",
      " given\n",
      "-3.3378587\n",
      "\n",
      "TopLogprob(token=' given', bytes=[32, 103, 105, 118, 101, 110], logprob=-3.3378587)\n",
      "\n",
      " doesn't\n",
      "-3.9628587\n",
      "\n",
      "TopLogprob(token=\" doesn't\", bytes=[32, 100, 111, 101, 115, 110, 39, 116], logprob=-3.9628587)\n",
      "\n",
      " you\n",
      "-4.4628587\n",
      "\n",
      "TopLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-4.4628587)\n",
      "\n",
      "[TopLogprob(token=' not', bytes=[32, 110, 111, 116], logprob=-2.220075e-06), TopLogprob(token=' appear', bytes=[32, 97, 112, 112, 101, 97, 114], logprob=-13.875002), TopLogprob(token=' seem', bytes=[32, 115, 101, 101, 109], logprob=-15.000002), TopLogprob(token=' **', bytes=[32, 42, 42], logprob=-15.250002), TopLogprob(token='not', bytes=[110, 111, 116], logprob=-15.875002), TopLogprob(token=\"'t\", bytes=[39, 116], logprob=-16.375002), TopLogprob(token=' no', bytes=[32, 110, 111], logprob=-16.875002), TopLogprob(token=\"n't\", bytes=[110, 39, 116], logprob=-17.000002)]\n",
      "\n",
      " not\n",
      "-2.220075e-06\n",
      "\n",
      "TopLogprob(token=' not', bytes=[32, 110, 111, 116], logprob=-2.220075e-06)\n",
      "\n",
      " appear\n",
      "-13.875002\n",
      "\n",
      "TopLogprob(token=' appear', bytes=[32, 97, 112, 112, 101, 97, 114], logprob=-13.875002)\n",
      "\n",
      " seem\n",
      "-15.000002\n",
      "\n",
      "TopLogprob(token=' seem', bytes=[32, 115, 101, 101, 109], logprob=-15.000002)\n",
      "\n",
      " **\n",
      "-15.250002\n",
      "\n",
      "TopLogprob(token=' **', bytes=[32, 42, 42], logprob=-15.250002)\n",
      "\n",
      "not\n",
      "-15.875002\n",
      "\n",
      "TopLogprob(token='not', bytes=[110, 111, 116], logprob=-15.875002)\n",
      "\n",
      "'t\n",
      "-16.375002\n",
      "\n",
      "TopLogprob(token=\"'t\", bytes=[39, 116], logprob=-16.375002)\n",
      "\n",
      " no\n",
      "-16.875002\n",
      "\n",
      "TopLogprob(token=' no', bytes=[32, 110, 111], logprob=-16.875002)\n",
      "\n",
      "n't\n",
      "-17.000002\n",
      "\n",
      "TopLogprob(token=\"n't\", bytes=[110, 39, 116], logprob=-17.000002)\n",
      "\n",
      "[TopLogprob(token=' appear', bytes=[32, 97, 112, 112, 101, 97, 114], logprob=-0.8023535), TopLogprob(token=' contain', bytes=[32, 99, 111, 110, 116, 97, 105, 110], logprob=-1.6773535), TopLogprob(token=' seem', bytes=[32, 115, 101, 101, 109], logprob=-2.1773534), TopLogprob(token=' resemble', bytes=[32, 114, 101, 115, 101, 109, 98, 108, 101], logprob=-2.4273534), TopLogprob(token=' represent', bytes=[32, 114, 101, 112, 114, 101, 115, 101, 110, 116], logprob=-2.9273534), TopLogprob(token=' form', bytes=[32, 102, 111, 114, 109], logprob=-3.5523534), TopLogprob(token=' provide', bytes=[32, 112, 114, 111, 118, 105, 100, 101], logprob=-3.6773534), TopLogprob(token=' present', bytes=[32, 112, 114, 101, 115, 101, 110, 116], logprob=-4.4273534)]\n",
      "\n",
      " appear\n",
      "-0.8023535\n",
      "\n",
      "TopLogprob(token=' appear', bytes=[32, 97, 112, 112, 101, 97, 114], logprob=-0.8023535)\n",
      "\n",
      " contain\n",
      "-1.6773535\n",
      "\n",
      "TopLogprob(token=' contain', bytes=[32, 99, 111, 110, 116, 97, 105, 110], logprob=-1.6773535)\n",
      "\n",
      " seem\n",
      "-2.1773534\n",
      "\n",
      "TopLogprob(token=' seem', bytes=[32, 115, 101, 101, 109], logprob=-2.1773534)\n",
      "\n",
      " resemble\n",
      "-2.4273534\n",
      "\n",
      "TopLogprob(token=' resemble', bytes=[32, 114, 101, 115, 101, 109, 98, 108, 101], logprob=-2.4273534)\n",
      "\n",
      " represent\n",
      "-2.9273534\n",
      "\n",
      "TopLogprob(token=' represent', bytes=[32, 114, 101, 112, 114, 101, 115, 101, 110, 116], logprob=-2.9273534)\n",
      "\n",
      " form\n",
      "-3.5523534\n",
      "\n",
      "TopLogprob(token=' form', bytes=[32, 102, 111, 114, 109], logprob=-3.5523534)\n",
      "\n",
      " provide\n",
      "-3.6773534\n",
      "\n",
      "TopLogprob(token=' provide', bytes=[32, 112, 114, 111, 118, 105, 100, 101], logprob=-3.6773534)\n",
      "\n",
      " present\n",
      "-4.4273534\n",
      "\n",
      "TopLogprob(token=' present', bytes=[32, 112, 114, 101, 115, 101, 110, 116], logprob=-4.4273534)\n",
      "\n",
      "[TopLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.005310012), TopLogprob(token=' as', bytes=[32, 97, 115], logprob=-5.25531), TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-10.75531), TopLogprob(token=' like', bytes=[32, 108, 105, 107, 101], logprob=-11.13031), TopLogprob(token=' related', bytes=[32, 114, 101, 108, 97, 116, 101, 100], logprob=-11.88031), TopLogprob(token=' directly', bytes=[32, 100, 105, 114, 101, 99, 116, 108, 121], logprob=-11.88031), TopLogprob(token=' relevant', bytes=[32, 114, 101, 108, 101, 118, 97, 110, 116], logprob=-12.13031), TopLogprob(token=' formatted', bytes=[32, 102, 111, 114, 109, 97, 116, 116, 101, 100], logprob=-12.25531)]\n",
      "\n",
      " to\n",
      "-0.005310012\n",
      "\n",
      "TopLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.005310012)\n",
      "\n",
      " as\n",
      "-5.25531\n",
      "\n",
      "TopLogprob(token=' as', bytes=[32, 97, 115], logprob=-5.25531)\n",
      "\n",
      " in\n",
      "-10.75531\n",
      "\n",
      "TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-10.75531)\n",
      "\n",
      " like\n",
      "-11.13031\n",
      "\n",
      "TopLogprob(token=' like', bytes=[32, 108, 105, 107, 101], logprob=-11.13031)\n",
      "\n",
      " related\n",
      "-11.88031\n",
      "\n",
      "TopLogprob(token=' related', bytes=[32, 114, 101, 108, 97, 116, 101, 100], logprob=-11.88031)\n",
      "\n",
      " directly\n",
      "-11.88031\n",
      "\n",
      "TopLogprob(token=' directly', bytes=[32, 100, 105, 114, 101, 99, 116, 108, 121], logprob=-11.88031)\n",
      "\n",
      " relevant\n",
      "-12.13031\n",
      "\n",
      "TopLogprob(token=' relevant', bytes=[32, 114, 101, 108, 101, 118, 97, 110, 116], logprob=-12.13031)\n",
      "\n",
      " formatted\n",
      "-12.25531\n",
      "\n",
      "TopLogprob(token=' formatted', bytes=[32, 102, 111, 114, 109, 97, 116, 116, 101, 100], logprob=-12.25531)\n",
      "\n",
      "[TopLogprob(token=' be', bytes=[32, 98, 101], logprob=-0.018437408), TopLogprob(token=' contain', bytes=[32, 99, 111, 110, 116, 97, 105, 110], logprob=-4.2684374), TopLogprob(token=' represent', bytes=[32, 114, 101, 112, 114, 101, 115, 101, 110, 116], logprob=-6.6434374), TopLogprob(token=' form', bytes=[32, 102, 111, 114, 109], logprob=-6.8934374), TopLogprob(token=' resemble', bytes=[32, 114, 101, 115, 101, 109, 98, 108, 101], logprob=-8.143437), TopLogprob(token=' correspond', bytes=[32, 99, 111, 114, 114, 101, 115, 112, 111, 110, 100], logprob=-8.268437), TopLogprob(token=' include', bytes=[32, 105, 110, 99, 108, 117, 100, 101], logprob=-8.393437), TopLogprob(token=' present', bytes=[32, 112, 114, 101, 115, 101, 110, 116], logprob=-8.768437)]\n",
      "\n",
      " be\n",
      "-0.018437408\n",
      "\n",
      "TopLogprob(token=' be', bytes=[32, 98, 101], logprob=-0.018437408)\n",
      "\n",
      " contain\n",
      "-4.2684374\n",
      "\n",
      "TopLogprob(token=' contain', bytes=[32, 99, 111, 110, 116, 97, 105, 110], logprob=-4.2684374)\n",
      "\n",
      " represent\n",
      "-6.6434374\n",
      "\n",
      "TopLogprob(token=' represent', bytes=[32, 114, 101, 112, 114, 101, 115, 101, 110, 116], logprob=-6.6434374)\n",
      "\n",
      " form\n",
      "-6.8934374\n",
      "\n",
      "TopLogprob(token=' form', bytes=[32, 102, 111, 114, 109], logprob=-6.8934374)\n",
      "\n",
      " resemble\n",
      "-8.143437\n",
      "\n",
      "TopLogprob(token=' resemble', bytes=[32, 114, 101, 115, 101, 109, 98, 108, 101], logprob=-8.143437)\n",
      "\n",
      " correspond\n",
      "-8.268437\n",
      "\n",
      "TopLogprob(token=' correspond', bytes=[32, 99, 111, 114, 114, 101, 115, 112, 111, 110, 100], logprob=-8.268437)\n",
      "\n",
      " include\n",
      "-8.393437\n",
      "\n",
      "TopLogprob(token=' include', bytes=[32, 105, 110, 99, 108, 117, 100, 101], logprob=-8.393437)\n",
      "\n",
      " present\n",
      "-8.768437\n",
      "\n",
      "TopLogprob(token=' present', bytes=[32, 112, 114, 101, 115, 101, 110, 116], logprob=-8.768437)\n",
      "\n",
      "[TopLogprob(token=' a', bytes=[32, 97], logprob=-0.01343597), TopLogprob(token=' an', bytes=[32, 97, 110], logprob=-4.638436), TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-5.888436), TopLogprob(token=' formatted', bytes=[32, 102, 111, 114, 109, 97, 116, 116, 101, 100], logprob=-8.263436), TopLogprob(token=' formulated', bytes=[32, 102, 111, 114, 109, 117, 108, 97, 116, 101, 100], logprob=-9.013436), TopLogprob(token=' related', bytes=[32, 114, 101, 108, 97, 116, 101, 100], logprob=-9.513436), TopLogprob(token=' phr', bytes=[32, 112, 104, 114], logprob=-9.763436), TopLogprob(token=' structured', bytes=[32, 115, 116, 114, 117, 99, 116, 117, 114, 101, 100], logprob=-9.888436)]\n",
      "\n",
      " a\n",
      "-0.01343597\n",
      "\n",
      "TopLogprob(token=' a', bytes=[32, 97], logprob=-0.01343597)\n",
      "\n",
      " an\n",
      "-4.638436\n",
      "\n",
      "TopLogprob(token=' an', bytes=[32, 97, 110], logprob=-4.638436)\n",
      "\n",
      " in\n",
      "-5.888436\n",
      "\n",
      "TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-5.888436)\n",
      "\n",
      " formatted\n",
      "-8.263436\n",
      "\n",
      "TopLogprob(token=' formatted', bytes=[32, 102, 111, 114, 109, 97, 116, 116, 101, 100], logprob=-8.263436)\n",
      "\n",
      " formulated\n",
      "-9.013436\n",
      "\n",
      "TopLogprob(token=' formulated', bytes=[32, 102, 111, 114, 109, 117, 108, 97, 116, 101, 100], logprob=-9.013436)\n",
      "\n",
      " related\n",
      "-9.513436\n",
      "\n",
      "TopLogprob(token=' related', bytes=[32, 114, 101, 108, 97, 116, 101, 100], logprob=-9.513436)\n",
      "\n",
      " phr\n",
      "-9.763436\n",
      "\n",
      "TopLogprob(token=' phr', bytes=[32, 112, 104, 114], logprob=-9.763436)\n",
      "\n",
      " structured\n",
      "-9.888436\n",
      "\n",
      "TopLogprob(token=' structured', bytes=[32, 115, 116, 114, 117, 99, 116, 117, 114, 101, 100], logprob=-9.888436)\n",
      "\n",
      "[TopLogprob(token=' valid', bytes=[32, 118, 97, 108, 105, 100], logprob=-1.1622796), TopLogprob(token=' question', bytes=[32, 113, 117, 101, 115, 116, 105, 111, 110], logprob=-1.1622796), TopLogprob(token=' clear', bytes=[32, 99, 108, 101, 97, 114], logprob=-2.4122796), TopLogprob(token=' coherent', bytes=[32, 99, 111, 104, 101, 114, 101, 110, 116], logprob=-2.5372796), TopLogprob(token=' typical', bytes=[32, 116, 121, 112, 105, 99, 97, 108], logprob=-2.6622796), TopLogprob(token=' recognizable', bytes=[32, 114, 101, 99, 111, 103, 110, 105, 122, 97, 98, 108, 101], logprob=-3.6622796), TopLogprob(token=' standard', bytes=[32, 115, 116, 97, 110, 100, 97, 114, 100], logprob=-4.0372796), TopLogprob(token=' proper', bytes=[32, 112, 114, 111, 112, 101, 114], logprob=-4.4122796)]\n",
      "\n",
      " valid\n",
      "-1.1622796\n",
      "\n",
      "TopLogprob(token=' valid', bytes=[32, 118, 97, 108, 105, 100], logprob=-1.1622796)\n",
      "\n",
      " question\n",
      "-1.1622796\n",
      "\n",
      "TopLogprob(token=' question', bytes=[32, 113, 117, 101, 115, 116, 105, 111, 110], logprob=-1.1622796)\n",
      "\n",
      " clear\n",
      "-2.4122796\n",
      "\n",
      "TopLogprob(token=' clear', bytes=[32, 99, 108, 101, 97, 114], logprob=-2.4122796)\n",
      "\n",
      " coherent\n",
      "-2.5372796\n",
      "\n",
      "TopLogprob(token=' coherent', bytes=[32, 99, 111, 104, 101, 114, 101, 110, 116], logprob=-2.5372796)\n",
      "\n",
      " typical\n",
      "-2.6622796\n",
      "\n",
      "TopLogprob(token=' typical', bytes=[32, 116, 121, 112, 105, 99, 97, 108], logprob=-2.6622796)\n",
      "\n",
      " recognizable\n",
      "-3.6622796\n",
      "\n",
      "TopLogprob(token=' recognizable', bytes=[32, 114, 101, 99, 111, 103, 110, 105, 122, 97, 98, 108, 101], logprob=-3.6622796)\n",
      "\n",
      " standard\n",
      "-4.0372796\n",
      "\n",
      "TopLogprob(token=' standard', bytes=[32, 115, 116, 97, 110, 100, 97, 114, 100], logprob=-4.0372796)\n",
      "\n",
      " proper\n",
      "-4.4122796\n",
      "\n",
      "TopLogprob(token=' proper', bytes=[32, 112, 114, 111, 112, 101, 114], logprob=-4.4122796)\n",
      "\n",
      "[TopLogprob(token=' question', bytes=[32, 113, 117, 101, 115, 116, 105, 111, 110], logprob=-0.0461531), TopLogprob(token=' or', bytes=[32, 111, 114], logprob=-3.421153), TopLogprob(token=',', bytes=[44], logprob=-5.046153), TopLogprob(token=' natural', bytes=[32, 110, 97, 116, 117, 114, 97, 108], logprob=-6.171153), TopLogprob(token=' human', bytes=[32, 104, 117, 109, 97, 110], logprob=-6.421153), TopLogprob(token='ly', bytes=[108, 121], logprob=-8.296153), TopLogprob(token=' user', bytes=[32, 117, 115, 101, 114], logprob=-8.796153), TopLogprob(token=' class', bytes=[32, 99, 108, 97, 115, 115], logprob=-8.921153)]\n",
      "\n",
      " question\n",
      "-0.0461531\n",
      "\n",
      "TopLogprob(token=' question', bytes=[32, 113, 117, 101, 115, 116, 105, 111, 110], logprob=-0.0461531)\n",
      "\n",
      " or\n",
      "-3.421153\n",
      "\n",
      "TopLogprob(token=' or', bytes=[32, 111, 114], logprob=-3.421153)\n",
      "\n",
      ",\n",
      "-5.046153\n",
      "\n",
      "TopLogprob(token=',', bytes=[44], logprob=-5.046153)\n",
      "\n",
      " natural\n",
      "-6.171153\n",
      "\n",
      "TopLogprob(token=' natural', bytes=[32, 110, 97, 116, 117, 114, 97, 108], logprob=-6.171153)\n",
      "\n",
      " human\n",
      "-6.421153\n",
      "\n",
      "TopLogprob(token=' human', bytes=[32, 104, 117, 109, 97, 110], logprob=-6.421153)\n",
      "\n",
      "ly\n",
      "-8.296153\n",
      "\n",
      "TopLogprob(token='ly', bytes=[108, 121], logprob=-8.296153)\n",
      "\n",
      " user\n",
      "-8.796153\n",
      "\n",
      "TopLogprob(token=' user', bytes=[32, 117, 115, 101, 114], logprob=-8.796153)\n",
      "\n",
      " class\n",
      "-8.921153\n",
      "\n",
      "TopLogprob(token=' class', bytes=[32, 99, 108, 97, 115, 115], logprob=-8.921153)\n",
      "\n",
      "[TopLogprob(token=' related', bytes=[32, 114, 101, 108, 97, 116, 101, 100], logprob=-1.3656905), TopLogprob(token=',', bytes=[44], logprob=-1.8656905), TopLogprob(token=' that', bytes=[32, 116, 104, 97, 116], logprob=-1.8656905), TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-2.6156905), TopLogprob(token=' but', bytes=[32, 98, 117, 116], logprob=-2.6156905), TopLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-3.1156905), TopLogprob(token=' from', bytes=[32, 102, 114, 111, 109], logprob=-3.1156905), TopLogprob(token='.', bytes=[46], logprob=-3.2406905)]\n",
      "\n",
      " related\n",
      "-1.3656905\n",
      "\n",
      "TopLogprob(token=' related', bytes=[32, 114, 101, 108, 97, 116, 101, 100], logprob=-1.3656905)\n",
      "\n",
      ",\n",
      "-1.8656905\n",
      "\n",
      "TopLogprob(token=',', bytes=[44], logprob=-1.8656905)\n",
      "\n",
      " that\n",
      "-1.8656905\n",
      "\n",
      "TopLogprob(token=' that', bytes=[32, 116, 104, 97, 116], logprob=-1.8656905)\n",
      "\n",
      " in\n",
      "-2.6156905\n",
      "\n",
      "TopLogprob(token=' in', bytes=[32, 105, 110], logprob=-2.6156905)\n",
      "\n",
      " but\n",
      "-2.6156905\n",
      "\n",
      "TopLogprob(token=' but', bytes=[32, 98, 117, 116], logprob=-2.6156905)\n",
      "\n",
      " for\n",
      "-3.1156905\n",
      "\n",
      "TopLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-3.1156905)\n",
      "\n",
      " from\n",
      "-3.1156905\n",
      "\n",
      "TopLogprob(token=' from', bytes=[32, 102, 114, 111, 109], logprob=-3.1156905)\n",
      "\n",
      ".\n",
      "-3.2406905\n",
      "\n",
      "TopLogprob(token='.', bytes=[46], logprob=-3.2406905)\n",
      "\n",
      "[TopLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.0007904516), TopLogprob(token=' directly', bytes=[32, 100, 105, 114, 101, 99, 116, 108, 121], logprob=-7.3757906), TopLogprob(token=' specifically', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 99, 97, 108, 108, 121], logprob=-9.125791), TopLogprob(token=' explicitly', bytes=[32, 101, 120, 112, 108, 105, 99, 105, 116, 108, 121], logprob=-10.250791), TopLogprob(token=' clearly', bytes=[32, 99, 108, 101, 97, 114, 108, 121], logprob=-11.625791), TopLogprob(token=' strictly', bytes=[32, 115, 116, 114, 105, 99, 116, 108, 121], logprob=-12.750791), TopLogprob(token=' any', bytes=[32, 97, 110, 121], logprob=-13.750791), TopLogprob(token=' content', bytes=[32, 99, 111, 110, 116, 101, 110, 116], logprob=-14.125791)]\n",
      "\n",
      " to\n",
      "-0.0007904516\n",
      "\n",
      "TopLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.0007904516)\n",
      "\n",
      " directly\n",
      "-7.3757906\n",
      "\n",
      "TopLogprob(token=' directly', bytes=[32, 100, 105, 114, 101, 99, 116, 108, 121], logprob=-7.3757906)\n",
      "\n",
      " specifically\n",
      "-9.125791\n",
      "\n",
      "TopLogprob(token=' specifically', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 99, 97, 108, 108, 121], logprob=-9.125791)\n",
      "\n",
      " explicitly\n",
      "-10.250791\n",
      "\n",
      "TopLogprob(token=' explicitly', bytes=[32, 101, 120, 112, 108, 105, 99, 105, 116, 108, 121], logprob=-10.250791)\n",
      "\n",
      " clearly\n",
      "-11.625791\n",
      "\n",
      "TopLogprob(token=' clearly', bytes=[32, 99, 108, 101, 97, 114, 108, 121], logprob=-11.625791)\n",
      "\n",
      " strictly\n",
      "-12.750791\n",
      "\n",
      "TopLogprob(token=' strictly', bytes=[32, 115, 116, 114, 105, 99, 116, 108, 121], logprob=-12.750791)\n",
      "\n",
      " any\n",
      "-13.750791\n",
      "\n",
      "TopLogprob(token=' any', bytes=[32, 97, 110, 121], logprob=-13.750791)\n",
      "\n",
      " content\n",
      "-14.125791\n",
      "\n",
      "TopLogprob(token=' content', bytes=[32, 99, 111, 110, 116, 101, 110, 116], logprob=-14.125791)\n",
      "\n",
      "[TopLogprob(token=' any', bytes=[32, 97, 110, 121], logprob=-0.7639222), TopLogprob(token=' \"', bytes=[32, 34], logprob=-1.3889222), TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-1.8889222), TopLogprob(token=' Math', bytes=[32, 77, 97, 116, 104], logprob=-2.2639222), TopLogprob(token=' a', bytes=[32, 97], logprob=-4.013922), TopLogprob(token=' one', bytes=[32, 111, 110, 101], logprob=-4.888922), TopLogprob(token=' specific', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 99], logprob=-6.763922), TopLogprob(token=' math', bytes=[32, 109, 97, 116, 104], logprob=-6.763922)]\n",
      "\n",
      " any\n",
      "-0.7639222\n",
      "\n",
      "TopLogprob(token=' any', bytes=[32, 97, 110, 121], logprob=-0.7639222)\n",
      "\n",
      " \"\n",
      "-1.3889222\n",
      "\n",
      "TopLogprob(token=' \"', bytes=[32, 34], logprob=-1.3889222)\n",
      "\n",
      " the\n",
      "-1.8889222\n",
      "\n",
      "TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-1.8889222)\n",
      "\n",
      " Math\n",
      "-2.2639222\n",
      "\n",
      "TopLogprob(token=' Math', bytes=[32, 77, 97, 116, 104], logprob=-2.2639222)\n",
      "\n",
      " a\n",
      "-4.013922\n",
      "\n",
      "TopLogprob(token=' a', bytes=[32, 97], logprob=-4.013922)\n",
      "\n",
      " one\n",
      "-4.888922\n",
      "\n",
      "TopLogprob(token=' one', bytes=[32, 111, 110, 101], logprob=-4.888922)\n",
      "\n",
      " specific\n",
      "-6.763922\n",
      "\n",
      "TopLogprob(token=' specific', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 99], logprob=-6.763922)\n",
      "\n",
      " math\n",
      "-6.763922\n",
      "\n",
      "TopLogprob(token=' math', bytes=[32, 109, 97, 116, 104], logprob=-6.763922)\n",
      "\n",
      "[TopLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.271632), TopLogprob(token=' category', bytes=[32, 99, 97, 116, 101, 103, 111, 114, 121], logprob=-2.021632), TopLogprob(token=' specific', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 99], logprob=-2.521632), TopLogprob(token=' subject', bytes=[32, 115, 117, 98, 106, 101, 99, 116], logprob=-5.521632), TopLogprob(token=' known', bytes=[32, 107, 110, 111, 119, 110], logprob=-5.521632), TopLogprob(token=' specified', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 101, 100], logprob=-6.021632), TopLogprob(token=' academic', bytes=[32, 97, 99, 97, 100, 101, 109, 105, 99], logprob=-6.396632), TopLogprob(token=' particular', bytes=[32, 112, 97, 114, 116, 105, 99, 117, 108, 97, 114], logprob=-6.646632)]\n",
      "\n",
      " of\n",
      "-0.271632\n",
      "\n",
      "TopLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.271632)\n",
      "\n",
      " category\n",
      "-2.021632\n",
      "\n",
      "TopLogprob(token=' category', bytes=[32, 99, 97, 116, 101, 103, 111, 114, 121], logprob=-2.021632)\n",
      "\n",
      " specific\n",
      "-2.521632\n",
      "\n",
      "TopLogprob(token=' specific', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 99], logprob=-2.521632)\n",
      "\n",
      " subject\n",
      "-5.521632\n",
      "\n",
      "TopLogprob(token=' subject', bytes=[32, 115, 117, 98, 106, 101, 99, 116], logprob=-5.521632)\n",
      "\n",
      " known\n",
      "-5.521632\n",
      "\n",
      "TopLogprob(token=' known', bytes=[32, 107, 110, 111, 119, 110], logprob=-5.521632)\n",
      "\n",
      " specified\n",
      "-6.021632\n",
      "\n",
      "TopLogprob(token=' specified', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 101, 100], logprob=-6.021632)\n",
      "\n",
      " academic\n",
      "-6.396632\n",
      "\n",
      "TopLogprob(token=' academic', bytes=[32, 97, 99, 97, 100, 101, 109, 105, 99], logprob=-6.396632)\n",
      "\n",
      " particular\n",
      "-6.646632\n",
      "\n",
      "TopLogprob(token=' particular', bytes=[32, 112, 97, 114, 116, 105, 99, 117, 108, 97, 114], logprob=-6.646632)\n",
      "\n",
      "[TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.0011067559), TopLogprob(token=' these', bytes=[32, 116, 104, 101, 115, 101], logprob=-7.5636067), TopLogprob(token=' \"', bytes=[32, 34], logprob=-8.126107), TopLogprob(token=' those', bytes=[32, 116, 104, 111, 115, 101], logprob=-8.251107), TopLogprob(token=' Math', bytes=[32, 77, 97, 116, 104], logprob=-10.813607), TopLogprob(token=' your', bytes=[32, 121, 111, 117, 114], logprob=-13.001107), TopLogprob(token=' our', bytes=[32, 111, 117, 114], logprob=-13.001107), TopLogprob(token=' specified', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 101, 100], logprob=-13.719857)]\n",
      "\n",
      " the\n",
      "-0.0011067559\n",
      "\n",
      "TopLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.0011067559)\n",
      "\n",
      " these\n",
      "-7.5636067\n",
      "\n",
      "TopLogprob(token=' these', bytes=[32, 116, 104, 101, 115, 101], logprob=-7.5636067)\n",
      "\n",
      " \"\n",
      "-8.126107\n",
      "\n",
      "TopLogprob(token=' \"', bytes=[32, 34], logprob=-8.126107)\n",
      "\n",
      " those\n",
      "-8.251107\n",
      "\n",
      "TopLogprob(token=' those', bytes=[32, 116, 104, 111, 115, 101], logprob=-8.251107)\n",
      "\n",
      " Math\n",
      "-10.813607\n",
      "\n",
      "TopLogprob(token=' Math', bytes=[32, 77, 97, 116, 104], logprob=-10.813607)\n",
      "\n",
      " your\n",
      "-13.001107\n",
      "\n",
      "TopLogprob(token=' your', bytes=[32, 121, 111, 117, 114], logprob=-13.001107)\n",
      "\n",
      " our\n",
      "-13.001107\n",
      "\n",
      "TopLogprob(token=' our', bytes=[32, 111, 117, 114], logprob=-13.001107)\n",
      "\n",
      " specified\n",
      "-13.719857\n",
      "\n",
      "TopLogprob(token=' specified', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 101, 100], logprob=-13.719857)\n",
      "\n",
      "[TopLogprob(token=' categories', bytes=[32, 99, 97, 116, 101, 103, 111, 114, 105, 101, 115], logprob=-0.69576895), TopLogprob(token=' specified', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 101, 100], logprob=-1.320769), TopLogprob(token=' given', bytes=[32, 103, 105, 118, 101, 110], logprob=-1.945769), TopLogprob(token=' provided', bytes=[32, 112, 114, 111, 118, 105, 100, 101, 100], logprob=-3.3207688), TopLogprob(token=' mentioned', bytes=[32, 109, 101, 110, 116, 105, 111, 110, 101, 100], logprob=-3.5707688), TopLogprob(token=' specific', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 99], logprob=-4.820769), TopLogprob(token=' three', bytes=[32, 116, 104, 114, 101, 101], logprob=-5.320769), TopLogprob(token=' listed', bytes=[32, 108, 105, 115, 116, 101, 100], logprob=-5.320769)]\n",
      "\n",
      " categories\n",
      "-0.69576895\n",
      "\n",
      "TopLogprob(token=' categories', bytes=[32, 99, 97, 116, 101, 103, 111, 114, 105, 101, 115], logprob=-0.69576895)\n",
      "\n",
      " specified\n",
      "-1.320769\n",
      "\n",
      "TopLogprob(token=' specified', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 101, 100], logprob=-1.320769)\n",
      "\n",
      " given\n",
      "-1.945769\n",
      "\n",
      "TopLogprob(token=' given', bytes=[32, 103, 105, 118, 101, 110], logprob=-1.945769)\n",
      "\n",
      " provided\n",
      "-3.3207688\n",
      "\n",
      "TopLogprob(token=' provided', bytes=[32, 112, 114, 111, 118, 105, 100, 101, 100], logprob=-3.3207688)\n",
      "\n",
      " mentioned\n",
      "-3.5707688\n",
      "\n",
      "TopLogprob(token=' mentioned', bytes=[32, 109, 101, 110, 116, 105, 111, 110, 101, 100], logprob=-3.5707688)\n",
      "\n",
      " specific\n",
      "-4.820769\n",
      "\n",
      "TopLogprob(token=' specific', bytes=[32, 115, 112, 101, 99, 105, 102, 105, 99], logprob=-4.820769)\n",
      "\n",
      " three\n",
      "-5.320769\n",
      "\n",
      "TopLogprob(token=' three', bytes=[32, 116, 104, 114, 101, 101], logprob=-5.320769)\n",
      "\n",
      " listed\n",
      "-5.320769\n",
      "\n",
      "TopLogprob(token=' listed', bytes=[32, 108, 105, 115, 116, 101, 100], logprob=-5.320769)\n",
      "\n",
      "[TopLogprob(token='.', bytes=[46], logprob=-1.3264381), TopLogprob(token=' \"', bytes=[32, 34], logprob=-1.3264381), TopLogprob(token=',', bytes=[44], logprob=-1.5764381), TopLogprob(token=' mentioned', bytes=[32, 109, 101, 110, 116, 105, 111, 110, 101, 100], logprob=-2.826438), TopLogprob(token=';', bytes=[59], logprob=-3.076438), TopLogprob(token=':', bytes=[58], logprob=-3.326438), TopLogprob(token=' provided', bytes=[32, 112, 114, 111, 118, 105, 100, 101, 100], logprob=-3.326438), TopLogprob(token=' but', bytes=[32, 98, 117, 116], logprob=-4.076438)]\n",
      "\n",
      ".\n",
      "-1.3264381\n",
      "\n",
      "TopLogprob(token='.', bytes=[46], logprob=-1.3264381)\n",
      "\n",
      " \"\n",
      "-1.3264381\n",
      "\n",
      "TopLogprob(token=' \"', bytes=[32, 34], logprob=-1.3264381)\n",
      "\n",
      ",\n",
      "-1.5764381\n",
      "\n",
      "TopLogprob(token=',', bytes=[44], logprob=-1.5764381)\n",
      "\n",
      " mentioned\n",
      "-2.826438\n",
      "\n",
      "TopLogprob(token=' mentioned', bytes=[32, 109, 101, 110, 116, 105, 111, 110, 101, 100], logprob=-2.826438)\n",
      "\n",
      ";\n",
      "-3.076438\n",
      "\n",
      "TopLogprob(token=';', bytes=[59], logprob=-3.076438)\n",
      "\n",
      ":\n",
      "-3.326438\n",
      "\n",
      "TopLogprob(token=':', bytes=[58], logprob=-3.326438)\n",
      "\n",
      " provided\n",
      "-3.326438\n",
      "\n",
      "TopLogprob(token=' provided', bytes=[32, 112, 114, 111, 118, 105, 100, 101, 100], logprob=-3.326438)\n",
      "\n",
      " but\n",
      "-4.076438\n",
      "\n",
      "TopLogprob(token=' but', bytes=[32, 98, 117, 116], logprob=-4.076438)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for logprob in logprobs:\n",
    "    top_logprobs = logprob.top_logprobs\n",
    "    print(top_logprobs)\n",
    "    print()\n",
    "    for top_logprob in top_logprobs:\n",
    "        print(top_logprob.token)\n",
    "        print(top_logprob.logprob)\n",
    "        print()\n",
    "        print(top_logprob)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "\n",
    "def entropy_calculation(probability_distribution):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a given probability distribution.\n",
    "\n",
    "    Parameters:\n",
    "    probability_distribution (list): A list of probabilities for each category.\n",
    "\n",
    "    Returns:\n",
    "    float: The calculated entropy.\n",
    "    \"\"\"\n",
    "    return -np.sum(np.fromiter((p * np.log(p) for p in probability_distribution if p > 0), dtype=float))\n",
    "\n",
    "def calculate_confidence(probability_distribution):\n",
    "    \"\"\"\n",
    "    Calculate the confidence of a given probability distribution.\n",
    "\n",
    "    Parameters:\n",
    "    probability_distribution (list): A list of probabilities for each category.\n",
    "\n",
    "    Returns:\n",
    "    float: The calculated confidence.\n",
    "    \"\"\"\n",
    "    entropy = entropy_calculation(probability_distribution)\n",
    "    max_entropy = np.log(len(probability_distribution))\n",
    "    \n",
    "    normalized_entropy = entropy / max_entropy\n",
    "    confidence = 1 - normalized_entropy\n",
    "    return confidence\n",
    "\n",
    "def calculate_average_confidence(confidence_list):\n",
    "    \"\"\"\n",
    "    Calculate the average confidence of a given list of confidence values.\n",
    "\n",
    "    Parameters:\n",
    "    confidence_list (list): A list of confidence values.\n",
    "\n",
    "    Returns:\n",
    "    float: The average confidence.\n",
    "    \"\"\"\n",
    "    return np.mean(confidence_list)\n",
    "\n",
    "def extract_and_normalize_logprobs(logprobs):\n",
    "    \"\"\"\n",
    "    Extract the top logprobs from a given logprobs object and normalize them.\n",
    "\n",
    "    Parameters:\n",
    "    logprobs (list): A list of logprobs objects.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of normalized probabilities.\n",
    "    \"\"\"\n",
    "    # Extract top logprobs\n",
    "    top_logprobs = [np.exp(logprob.logprob) for logprob in logprobs]\n",
    "    \n",
    "    # Normalize the probability distribution\n",
    "    total = sum(top_logprobs)\n",
    "    return [p / total for p in top_logprobs]\n",
    "\n",
    "def extract_keywords_from_response(text: str):\n",
    "    \"\"\"\n",
    "    Extract keywords from a given text.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The text to extract keywords from.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of keywords.\n",
    "    \"\"\"\n",
    "    keyword_answer = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': 'You are a helpful assistant that can extract keywords from a given text. You always have to extract exactly 3 keywords. Even if the text contains less or more than 3 keywords, you have to extract exactly 3 keywords. Display your answer in the JSON format of {\"keywords\": [keyword1, keyword2, keyword3]}'},\n",
    "            {'role': 'user', 'content': f'Please extract keywords from the following text: {text}'}\n",
    "        ],\n",
    "        max_tokens=100,\n",
    "        response_format={'type': 'json_object'}\n",
    "    )\n",
    "    \n",
    "    keyword_answer_json = json.loads(keyword_answer.choices[0].message.content)\n",
    "    keywords = keyword_answer_json['keywords']\n",
    "\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5151143475533965, 0.3124326356760252, 0.11493754341621697, 0.0256460324695276, 0.019973150169942767, 0.005722404476578303, 0.003470813762321565, 0.002703072475991044]\n",
      "[0.3424724543716436, 0.18331229515537065, 0.18331229515537065, 0.14276375901361912, 0.0865905796194682, 0.03185489404112124, 0.024808616423881852, 0.004885106219524855]\n",
      "[0.5635237638007529, 0.16145224532839914, 0.1257391350903938, 0.046256842750434575, 0.036024865356449276, 0.036024865356449276, 0.019282720892897325, 0.011695561424223594]\n",
      "[0.9999982204437105, 9.422440123183021e-07, 3.0590184345276804e-07, 2.3823659522400205e-07, 1.275188602850998e-07, 7.734409845452483e-08, 4.6911567060501824e-08, 4.1399312626282396e-08]\n",
      "[0.46881458757072847, 0.1954309958294808, 0.1185349026822416, 0.09231507503022254, 0.05599192335950213, 0.02997031688293293, 0.026448711818667113, 0.012493486826224313]\n",
      "[0.9947201893185522, 0.005219812558124044, 2.13321808766774e-05, 1.4661379209770182e-05, 6.925545155747923e-06, 6.925545155747923e-06, 5.393619990492857e-06, 4.759852935328301e-06]\n",
      "[0.9827327594376936, 0.014017930062799, 0.0013038706045820528, 0.0010154554478722887, 0.0002909329731863893, 0.0002567474476967157, 0.00022657882733885203, 0.00015572519883102383]\n",
      "[0.9869897882691286, 0.009676107117786149, 0.00277225110417876, 0.000257859520418885, 0.00012180421275172, 7.387798951607869e-05, 5.7536236086863125e-05, 5.077555013303273e-05]\n",
      "[0.34016499172853526, 0.34016499172853526, 0.09745890185413222, 0.08600717901556777, 0.07590106908127736, 0.027922442877935355, 0.019190795627658318, 0.013189628086358228]\n",
      "[0.9565654778755805, 0.03273187396798921, 0.006445288135609303, 0.0020924786960610582, 0.0016296240470525841, 0.0002499109417054472, 0.00015157864834201035, 0.00013376768765978374]\n",
      "[0.3042312080712811, 0.18452555533664558, 0.18452555533664558, 0.08716370046699262, 0.08716370046699262, 0.0528674567472394, 0.0528674567472394, 0.04665536682696385]\n",
      "[0.9992159787599013, 0.0006262352384718207, 0.0001088233233875402, 3.532976044390053e-05, 8.932762350514329e-06, 2.900043337420249e-06, 1.0668663223431256e-06, 7.332457852495838e-07]\n",
      "[0.46664878084498246, 0.24977909305173052, 0.15149867809108936, 0.10412341720301047, 0.018093940431690773, 0.007542676552297238, 0.001156706912599562, 0.001156706912599562]\n",
      "[0.7711633660099015, 0.13400809915605957, 0.0812800207879608, 0.004046693951911605, 0.004046693951911605, 0.002454443952308069, 0.0016869130138146764, 0.0013137691761322136]\n",
      "[0.9988985682811813, 0.0005190024351318531, 0.0002957185848160665, 0.0002609707351368786, 2.0123902247800737e-05, 2.2578392573385982e-06, 2.2578392573385982e-06, 1.1003829715028174e-06]\n",
      "[0.5034250769197524, 0.26946401235114825, 0.14423369218553445, 0.03646799572721516, 0.028401303629399816, 0.008137108099483991, 0.004935405543733037, 0.004935405543733037]\n",
      "[0.2848756616196799, 0.2848756616196799, 0.2218613883473913, 0.06356435835602461, 0.04950397206310336, 0.03855373220788985, 0.03855373220788985, 0.018211493578341165]\n",
      "Average Confidence: 0.5799291864720607\n"
     ]
    }
   ],
   "source": [
    "confidence_list = []\n",
    "\n",
    "for logprob in logprobs:\n",
    "    top_logprobs = logprob.top_logprobs\n",
    "    normalized_probability_distribution = extract_and_normalize_logprobs(top_logprobs)\n",
    "    print(normalized_probability_distribution)\n",
    "    confidence = calculate_confidence(normalized_probability_distribution)\n",
    "    confidence_list.append(confidence)\n",
    "\n",
    "average_confidence = calculate_average_confidence(confidence_list)\n",
    "print(f\"Average Confidence: {average_confidence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted keywords: ['input', 'valid', 'question']\n",
      "Tokens related to keywords: {' valid', ' question', ' input'}\n",
      "Confidence for each keyword-related token: [0.1794794693256201, 0.23051188734749395, 0.8966630725609644]\n",
      "Average Confidence for keywords: 0.4355514764113595\n"
     ]
    }
   ],
   "source": [
    "# Extract keywords from the answer\n",
    "answer_text = response_to_check_logprob.choices[0].message.content\n",
    "keywords = extract_keywords_from_response(answer_text)\n",
    "print(\"Extracted keywords:\", keywords)\n",
    "\n",
    "confident_list_for_keywords = []\n",
    "keyword_tokens = set()\n",
    "\n",
    "for logprob in logprobs:\n",
    "    token = logprob.token.lower()\n",
    "    if any(keyword.lower() in token for keyword in keywords):\n",
    "        keyword_tokens.add(token)\n",
    "        top_logprobs = logprob.top_logprobs\n",
    "        normalized_probability_distribution = extract_and_normalize_logprobs(top_logprobs)\n",
    "        confidence = calculate_confidence(normalized_probability_distribution)\n",
    "        confident_list_for_keywords.append(confidence)\n",
    "\n",
    "if confident_list_for_keywords:\n",
    "    average_confidence_for_keywords = calculate_average_confidence(confident_list_for_keywords)\n",
    "    print(f\"Tokens related to keywords: {keyword_tokens}\")\n",
    "    print(f\"Confidence for each keyword-related token: {confident_list_for_keywords}\")\n",
    "    print(f\"Average Confidence for keywords: {average_confidence_for_keywords}\")\n",
    "else:\n",
    "    print(\"No tokens related to keywords found in the response.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
